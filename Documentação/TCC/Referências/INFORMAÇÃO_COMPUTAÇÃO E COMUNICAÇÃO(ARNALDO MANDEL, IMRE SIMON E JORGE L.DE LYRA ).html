<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2//EN">
<!-- saved from url=(0047)http://www.ime.usp.br/~is/infousp/imre/imre.htm -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>INFORMAÇÃO:COMPUTAÇÃO E COMUNICAÇÃO</title>
</head>
<body bgcolor="#ffffff">

<!-- Generation of PM publication page 1 -->

<table border="0" cellspacing="0" cellpadding="0" lang="en" dir="LTR" width="538" cols="7">
<!-- Some browsers do not display table correctly. -->
<!-- The following GIF images are here to work around the problem. -->
<tbody><tr valign="TOP" align="LEFT">
<td colspan="1" width="27"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="27" height="1"></td>
<td colspan="1" width="13"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="13" height="1"></td>
<td colspan="1" width="15"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="15" height="1"></td>
<td colspan="1" width="196"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="196" height="1"></td>
<td colspan="1" width="29"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="29" height="1"></td>
<td colspan="1" width="198"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="198" height="1"></td>
<td colspan="1" width="56"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/HtmlExp.gif" width="56" height="1"></td>
</tr><tr valign="TOP" align="LEFT">
<td colspan="1" height="57">
</td></tr><tr valign="TOP" align="LEFT">
<td colspan="3">
</td><td colspan="3" rowspan="3" height="671" width="419" valign="TOP">
<p align="CENTER"><b>Informação:computaçãoe comunicação
</b></p><p align="CENTER"><b>Arnaldo Mandel, Imre Simon e Jorge L. de 
Lyra 
</b></p><p align="JUSTIFY"><b>
</b></p><p align="JUSTIFY"><b>
</b></p><p align="JUSTIFY"><b>1. Introdução</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A"sociedade da informação" que se configura neste fim de século decorre de uma 
revolução tecnológica cujas origens remontam ao final da Segunda Guerra Mundial, e cujo complexo 
desenvolvimento transcorre durante toda a segunda metade do século, com potencial para modificar, a 
médio prazo, muitos aspectos da vida cotidiana. Segundo a National Science Foundation, a tecnologia 
eletrônica da informação alterará cada instituição da vida americana, com "efeito transformador", até 
1998. Embora muitos elementos tenham contribuído para essa transformação, dois pontos focais 
aparecem como determinantes do seu crescimento: computação e comunicação, diretamente ligados a 
dois objetos tecnológicos que proporcionaram a esse crescimento uma velocidade nunca 
vista: microcomputador e rede Internet. 
</p><p align="JUSTIFY">Dessa forma, nos últimos anos praticamente todo cidadão tem testemunhado uma invasão 
crescente do seu cotidiano por novas tecnologias de computação e de comunicação que causam 
mudanças dramáticas no papel, na quantidade, na qualidade e na velocidade de troca de informação com que 
ele lida no dia-a-dia. 
</p><p align="JUSTIFY">Essa invasão é alardeada pelos meios de comunicação de massa: há anos que temos cadernos 
de informática semanais nos maiores jornais diários do país, há anos que a 
<i>Gazeta Mercantil</i> mantém uma seção diária sobre informática e telecomunicações, há anos que o computador, as comunicações, 
as redes de computadores, especialmente a Internet e a teia mundial (World Wide Web) vêm 
ocupando espaços crescentes nas grandes revistas semanais internacionais e nacionais. Gostaríamos de 
realçar aqui a cobertura da revista <i>The 
Economist</i> que aborda regulamente alguns dos temas mais 
palpitantes da área, de forma não técnica, mas sempre com grande profundidade e grande originalidade 
(1). Ademais, há alguns meses, endereços eletrônicos de 
<i>e-mail</i> ou de páginas na teia rotineiramente 
fazem parte de anúncios em todos os meios de comunicação, até mesmo no Brasil, inclusive na televisão. 
</p><p align="JUSTIFY">Presenciamos também uma enxurrada de livros sobre informática, sobre computadores, sobre a 
teia mundial, sobre trabalho em grupo, sobre ensino a distância, sobre a Internet, sobre as Intranets, 
sobre Linux, Windows, Netscape, Java e tantos outros assuntos denotados por palavras que foram 
entrando no nosso vocabulário a partir dos primeiros anos da década de 1990 e que cada vez mais 
rapidamente vêm adquirindo adeptos em grandes números, forçados ou não a aderir. É impressionante o 
grande volume de traduções e textos originais em português, sem similar em outra área de atividade. 
</p><p align="JUSTIFY">Os jovens são um vetor irresistível e inexorável da inovação. Tudo indica que para eles não 
haverá uma transição brusca para a "sociedade da informação", tudo que terão de fazer é ir se adaptando 
à medida que surgirem novas ondas de conceitos, técnicas e produtos. 
</p><p align="JUSTIFY">As novidades afetam um número cada vez maior de aspectos da vida profissional e 
cotidiana: editoração eletrônica, compras a distância, jogos e diversão via computador, telefone pela 
Internet, correio eletrônico, navegação pela teia mundial, televisão sob demanda espreitando na esquina, 
distribuição e aquisição de 
<i>software</i>, busca e obtenção instantânea de informações de qualquer tipo. 
</p><p align="JUSTIFY">Fala-se, também, de novas tecnologias que terão o potencial para impactar algumas das 
instituições mais sólidas em que nossa civilização é baseada com a introdução do ensino a distância, 
telemedicina, biblioteca digital e dinheiro eletrônico, por exemplo. 
</p><p align="JUSTIFY">O uso da rede aumenta dramaticamente o grau de cooperação entre parceiros, muitas vezes 
geograficamente distantes, e impõe novos paradigmas, novas possibilidades e novos problemas para 
muitas atividades. A rede está rapidamente entrando nas residências; nos EUA 15% da população já tem 
acesso residencial à Internet (2). 
</p><p align="JUSTIFY">Entendemos que o fenômeno descrito baseia-se numa verdadeira revolução nas formas e 
métodos como a informação é gerada, armazenada, processada e transmitida. Essa revolução está sendo 
permitida pela convergência de extraordinários avanços nas tecnologias de computação e de 
comunicação, justificando o nosso título. Uma de suas características mais marcantes é a velocidade explosiva com





a qual ela se processa (3).
</p><p align="JUSTIFY">O objetivo deste documento é fazer uma reflexão sobre esses acontecimentos e tentar isolar 
alguns dos aspectos mais marcantes em que os mesmos se baseiam, evitando uma abordagem 
demasiadamente técnica. Procuraremos mostrar também a história da evolução destas tecnologias bem como 
alguns dos seus aspectos em estudo ou em desenvolvimento no momento, que têm alta probabilidade de 
passar para o cotidiano nos próximos anos. Pretendemos tocar também, se bem que de forma resumida, 
nos impactos acadêmicos, econômicos, culturais e sociais envolvidos nesta verdadeira revolução que 
está levando à "sociedade da informação". 
</p><p align="JUSTIFY">Neste trabalho examinaremos a relação desses acontecimentos com o meio acadêmico, tanto 
como produtor quanto como usuário pioneiro da nova tecnologia. Existem muito poucas fontes de 
informação e principalmente de reflexão sobre o que está ocorrendo, pois o fenômeno é novo demais e 
parece ser muito profundo. Gostaríamos de aliviar esta situação com o presente documento, 
apresentando também uma série de referências úteis. Recomendamos, em particular, a leitura de quatro textos 
(4) para detalhes além do escopo deste trabalho. Uma descrição muito acessível dos aspectos técnicos 
das redes computacionais pode ser encontrada no livro de Comer (5). Reflexões notáveis sobre 
novas organizações econômicas e empresariais podem ser encontradas em dois trabalhos (6). 
</p><p align="JUSTIFY">Uma versão mais curta deste artigo pode ser obtida pela leitura apenas das seções ímpares. 
As demais seções complementam o texto com uma abordagem mais detalhada e técnica. 
</p><p align="JUSTIFY">Esperamos que este documento seja útil para que pessoas dos mais diversos níveis, entre elas as 
que têm poder de decisão sobre a forma e o volume de participação das suas organizações neste 
processo, sejam elas empresas, universidades ou órgãos públicos, possam avaliar melhor os acontecimentos 
e possam se orientar com maior segurança sobre como enfrentar o futuro e como melhor se preparar 
para ele. Uma coisa é certa: os autores, embora observadores deste cenário já por longos períodos 
(que variam de 10 a 35 anos), ficaram surpresos com o quanto aprenderam com a redação e montagem 
deste documento, motivo pelo qual agradecem à Academia Brasileira de Ciências pela oportunidade. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>2. Os Elementos do Processo: Computadores, Discos e Cabos </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Neste fim de século, a informação e o conhecimento se tornaram insumos básicos da 
economia global. Se essa frase soa como clichê, não é para menos: variações dela têm sido repetidas nos 
últimos anos pela imprensa especializada e leiga. Suas manifestações concretas vão desde o 
conhecimento necessário na indústria de alta tecnologia à previsão do tempo para a agricultura e a aviação, e 
passam pelo fluxo permanente de dados que alimenta o mercado financeiro.
</p><p align="JUSTIFY"> Embora informação tenha sido sempre um elemento útil, a tecnologia recente permitiu pela 
primeira vez que se armazenasse e tratasse grande volume de dados, e que se comunicassem esses 
dados em grande velocidade em qualquer distância. O grande crescimento na escala da quantidade de 
dados se reflete numa mudança qualitativa da informação disponível; a facilidade de comunicação 
remove barreiras geográficas e permite que organizações funcionem de forma unificada. 
</p><p align="JUSTIFY">Informação se apresenta de várias formas, e está em geral constituída de duas partes: uma 
<i>forma de representação</i>, ou seja, 
<i>dados</i>, e um <i>mecanismo de 
interpretação</i>, que transforma dados em 
informação (e vice-versa). Por exemplo, o cérebro humano tem mecanismos para interpretar os 
desenhos de letras impressas como palavras e conceitos de uma língua, e extrair informação de um texto 
escrito. É de se notar que com o uso de mecanismos diferentes de interpretação, informações diferentes 
podem ser extraídas de um conjunto de dados, e por sua vez reapresentadas em outra forma, adequadas 
para outros interpretadores; isso configura uma 
<i>transformação de dados</i>, é uma das principais 
atividades envolvendo informação, e por si só pode gerar nova informação. Ela é executada por consultores 
e especialistas, que destrincham uma situação complicada para seu cliente, por tradutores, ao passar 
um texto de uma língua para outra, por computadores ao transformar uma grande massa de dados 
em relatórios inteligíveis ao ser humano. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>2. 1. Armazenamento de 
informações</b> 

</p><p align="JUSTIFY">O modo mais clássico de armazenamento de informação é através da palavra escrita, impressa. 
O acesso à informação estocada dessa forma é lento, difícil e de pouco rendimento. Para todas as 
etapas da manipulação da informação é necessária a presença do ser humano, e suas limitações na 
capacidade de aquisição de dados e processamento de grande volume constituem o principal gargalo do 
processo. Esse mecanismo é especialmente inconveniente para armazenamento de informação dinâmica, 
de atualização constante. Um exemplo pitoresco ocorre na prática legislativa brasileira: é comum 
encerrar-se diplomas legais com a expressão "revogam-se as disposições em contrário". Entretanto, é 
praticamente impossível saber quais disposições foram revogadas e, para uma dada lei, é difícil saber 
se não foi suplantada por uma lei posterior. A dificuldade está em consultar e interpretar o grande 
número de textos legais. 
</p><p align="JUSTIFY">Com o advento da computação surgiram meios bem mais eficientes de se armazenar 
informação, com vistas a uma recuperação expedita e posterior transformação. Os discos magnéticos são no 
momento o meio mais utilizado para combinar grande capacidade e alta velocidade de acesso. Já é 
viável para uma empresa média ter em um escritório uma capacidade de estocar o equivalente a uma 
biblioteca de porte razoável. 
</p><p align="JUSTIFY">O crescimento da capacidade dos discos é um exemplo de processo exponencial, a ser delineado 
mais adiante. Assim, enquanto na década de 70 o megabite (MB) era uma unidade cara até para empresas e 
de uso raro, o início dos anos 80 colocou 5 MB na mesa do indivíduo, em discos que simultaneamente 
foram barateando e aumentando de capacidade. Atualmente, discos de 1 gigabite são acessórios baratos 
de microcomputadores, e já se comercializam competitivamente capacidades de terabites 
(aproximadamente 1 milhão de 
<i>megabites</i>) (7). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>2. 2. Comunicação de dados </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A nova velocidade de comunicação de dados e informações é outro aspecto fundamental 
desse processo de crescente importância da informação. Termos como "aldeia global" deixaram de 
ser conceitos acadêmicos para virar lugar-comum do presente. Se tomarmos os meios de comunicação 
de massa, como rádio e TV, por exemplo, temos novamente aqui uma situação análoga à da 
informação impressa: grande massa de informação direto do produtor ao receptor humano, que deve de 
alguma forma integrá-la como conhecimento. A informação é efêmera, e mesmo se guardada em fitas, de 
difícil recuperação e transformação. Uma mudança qualitativa fundamental está em se poder 
transmitir informação como dados reutilizáveis. 
</p><p align="JUSTIFY">O progresso na comunicação de dados levou-a a atingir uma velocidade compatível com o 
volume de dados que se produz e consome atualmente. Novamente aqui é necessário que a informação 
transite automaticamente, uma vez que a presença do ser humano no meio do processo implica numa 
perda radical de eficiência.
</p><p align="JUSTIFY">Sobre a velocidade da comunicação é importante notar dois aspectos diferentes, a banda de 
passagem (volume de informação que pode ser passado simultaneamente), e a latência (tempo que cada 
bite de informação leva de fato para ir de um lugar ao outro). Quase sempre, ao se descrever um canal 
de comunicação, sua capacidade é descrita pela banda, o que pode dar uma idéia errada. Um 
exemplo interessante da diferença desses conceitos é resumido por Tanenbaum (8): com a pitoresca frase 
"<i>Never under estimate the bandwidth of a station wagon full of tapes hurtling down the 
highway"</i>. De fato, com a gigantesca capacidade de armazenamento de pequenas fitas hoje em dia, é possível, por 
exemplo, transferir em uma viagem São Paulo-Rio vários terabites, o que facilmente implementa uma banda 
da ordem de gigabites<i> </i>por segundo, impossível na presente tecnologia de telecomunicações. 
Entretanto, a latência envolvida é grande, envolvendo tempo de estrada, de tráfego urbano e de gravação e 
leitura das fitas. 
</p><p align="JUSTIFY">Com o uso de telecomunicações, obtém-se baixíssima latência, desde que a banda disponível 
não esteja sobrecarregada. É por isso que se pode estabelecer comunicação que, para todos os 
efeitos, parece instantânea. O tráfego de dados se faz, na maior parte, por cabos de cobre e fibras ópticas, 
com algum uso de rádio e microondas. As fibras são de uso relativamente recente e, por permitirem 
velocidades muito altas, vêm se transformando no meio preferido. 

</p><p align="JUSTIFY">O crescimento na capacidade dos canais de comunicação também é impressionante. Por 
exemplo, as linhas da espinha dorsal da rede que hoje é a Internet evoluíram de 56 Kbps (1980) para 448 
Kbps (1984), 1.5 Mbps (1988), 45 Mbps (1990), com perspectiva de gigabites/s até o fim do século. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>2. 3. Transformando dados em informação </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Essencial neste processo de mudança de escala na quantidade de informação que se pode tratar 
é a capacidade de processamento de dados em grande volume e com grande velocidade por 
computadores. Em todas as etapas, seja na produção, comunicação, armazenamento e tratamento de 
informações, encontram-se computadores capazes de lidar com grandes volumes de dados. 
</p><p align="JUSTIFY">Nas décadas de 60 e 70 já se pôde notar a diferença resultante de meios magnéticos 
para armazenamento de dados e computadores para seu processamento. Isso teve um forte impacto no 
modo de trabalho de muitas empresas e órgãos governamentais. A partir da década de 80, essa 
capacidade de processamento chegou até as pequenas empresas e o usuário individual. No presente, as 
capacidades de processamento e armazenamento de um computador doméstico são comparáveis às de 
supercomputadores de quinze anos atrás, e inimagináveis no início da década de 70. 
</p><p align="JUSTIFY">Com o acoplamento direto de máquinas de processamento aos meios de comunicação 
resolveu-se, em grande parte, o problema da latência na transmissão de dados do produtor ao consumidor. As 
redes de computadores permitem que dados trafeguem em grande volume e velocidade e sejam 
transformados em informação dentro de uma escala de tempo sem comparação na história. 
</p><p align="JUSTIFY">É interessante que, a partir do momento em que essa conjugação de meios se tornou possível, já 
ficou claro onde estava o futuro: 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">"<i>The information revolution produced a knowledge explosion. Advances in the development and 
use of computerized information-processing networks, some of them on a world wide basis, suggest 
not only further 'explosion' of knowledge but revolutionary steps in generation and reorganization, 
storage and distribution. </i>[...]<i> Anything that can be done anywhere in the world with any computing 
system could now be done at any standard teletypewriter or other operator's console -provided that 
the communications connections have been made and the computer files and programs modified to 
permit general access from remote points</i>" (9). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">O que estava para vir e concretizar essas previsões, muito além do que se poderia esperar em 
1977, era a total capilarização desses meios, através de dois elementos: 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">· o microcomputador, que trouxe o poder de processamento às mãos do indivíduo; 
</p><p align="JUSTIFY">· a Internet, que permitiu que todos os computadores a ela conectados se interligassem para troca 
de dados. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. Características 
Marcantes</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Tendo isolado os principais elementos do processo na seção anterior, examinamos aqui as 
características que mais contribuem para a manutenção do seu crescimento exponencial por longos 
períodos de tempo. Maiores considerações sobre o próprio processo exponencial de crescimento também 
serão feitas. Ao mesmo tempo, esperamos que esta enumeração de alguns dos aspectos mais marcantes 
do sistema, intercalados com exemplos, dêem, principalmente para o leitor leigo nessas técnicas, 
uma dimensão das enormes dificuldades que tiveram que ser transpostas para que a tecnologia chegasse 
ao seu estágio de desenvolvimento atual. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 1. Interatividade</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Algumas das características da Internet a tornam uma novidade única na história das 
comunicações. Ela é uma forma de comunicação rápida que permite o transporte de grandes quantidades de informa

</p><p align="JUSTIFY">ção, com completa liberdade quanto ao tipo e formato, nos dois sentidos, entre pessoas individuais 
a partir de muitos locais, como, por exemplo, suas residências ou locais de trabalho. Isso não só 
permite que uma determinada pessoa ou organização se comunique com um número grande de outras 
pessoas, como no caso da televisão tradicional, como também permite que a comunicação possa ser 
feita simultaneamente nos dois sentidos, em modo 
<i>full duplex</i>, permitindo uma completa 
interatividade entre os participantes. Basicamente, pode-se ter a interatividade de uma ligação telefônica com 
a capacidade de transmitir informação de um canal de televisão. Por outro lado, também é possível 
ter a capacidade de transmissão e registro permanente de mensagens como no telex ou no fax, 
combinada com a possibilidade de envio de grandes quantidades de informação em formatos arbitrários. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 2. Hipertexto</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">O hipertexto é um dos paradigmas básicos em que a teia mundial se baseia. Ele é uma espécie 
de texto multidimensional em que, numa página, trechos de texto se intercalam com referências a 
outras páginas. Clicando com o <i>mouse</i> numa referência dessas a página corrente é substituída pela 
página referenciada. É muito fácil formar uma idéia grosseira do que é um hipertexto: basta pensar nas 
edições mais modernas da <i>Enciclopédia Britânica 
</i>que se constituem de uma mistura de informações 
com apontadores para outros trechos da própria enciclopédia. 
</p><p align="JUSTIFY">A invenção do conceito costuma ser atribuída a Vannevar Bush que descreve o 
<i>memex</i> num artigo clássico, escrito em 1945, antes mesmo do aparecimento dos primeiros computadores (10). A seguir 
Doug Engelbart fez, em 1968, uma demonstração histórica numa conferência de computação realizando o 
<i>memex</i> com a utilização de um 
<i>mouse</i> (11). O termo "hipertexto" foi lançado por Ted Nelson, nos anos 60 (12). 
</p><p align="JUSTIFY">O hipertexto é muito apropriado para a representação de informações no computador por 
dois motivos: permite subdividir um texto em trechos coerentes e relativamente curtos, facilitando a 
sua organização e compreensão, e permite também fácil referência a outras partes do texto ou a 
outros textos, totalmente independentes, muitas vezes armazenados em locais distantes. Isso cria uma 
característica própria de leitura da informação que, após um curto processo de adaptação, passa a 
ser intuitivo para o usuário, que se refere a essa leitura como "navegação". 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 3. Multimídia</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A informação pode ser comunicada por múltiplos meios: textos, imagens, sons, filmes, 
animações, cheiros, sabores, diversas características detectadas pelo tato, etc. Alguns desses meios podem 
ser digitalizados, outros, como cheiro, sabor e tato, ainda não chegaram nessa fase. O termo 
multimídia costuma se referir à conjunção das múltiplas formas acima, que já podem ser digitalizadas e que 
são correntemente usadas em computadores, em geral num ambiente de hipertexto. É importante notar 
que a forte expansão das capacidades de processamento e de armazenamento dos computadores foi 
imprescindível para a viabilização do uso de vários dos meios acima mencionados. Por exemplo, 
o armazenamento e processamento de vídeos ou animações seria totalmente impensável quinze 
anos atrás, e ainda hoje apresenta sérias dificuldades técnicas. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 4. 
Digitalização</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Observa-se hoje um avanço muito forte da digitalização da informação, uma condição 
necessária para o amplo uso dos computadores no seu processamento. É importante notar que a digitalização 
da informação foi um dos marcos da invenção dos computadores, já que na época a idéia 
predominante era a da computação analógica, mais adequada às técnicas matemáticas dominantes na época. O 
livro <i>Computer and the Brain</i>, última obra de John von Neumann (13), dedica amplo espaço à discussão 
das vantagens e desvantagens de cada modo de computação: digital ou analógica. Verificamos hoje 
que a solução digital domina completamente o cenário, haja vista que já passamos da época da 
digitalização do sinal sonoro e que estamos no limiar da digitalização do sinal de televisão e da tecnologia 
telefônica, ao mesmo tempo em que fica cada vez mais raro o uso de sinais analógicos para efeito de processamento
da informação. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 5. Computação distribuída </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">O aparecimento de redes de computadores permitiu a utilização de um novo paradigma 
computacional que se mostrou, com o passar do tempo, extremamente poderoso. Estamos nos referindo à 
possibilidade de distribuição do processamento entre computadores diferentes. Mais do que a simples 
subdivisão de tarefas, esse paradigma permite a repartição e a especialização das tarefas 
computacionais conforme a natureza da função de cada computador. 
Um exemplo típico é a chamada arquitetura 
cliente/servidor, na qual muitos computadores "clientes" se comunicam com computadores "servidores" 
que nada mais são do que processos especializados na execução de certas tarefas, como cuidar de 
arquivos ou administrar bancos de dados. 
</p><p align="JUSTIFY">Numa tentativa de ilustrar este conceito, mencionamos que a mistura do paradigma 
cliente/servidor com a idéia de hipertexto levou ao estágio atual da teia mundial que se apóia sinergeticamente nos 
dois paradigmas. Para melhor apreciar esse ponto, sugerimos ao leitor a consulta do número especial 
da <i>Communications of the ACM</i> (Association for Computing Machinery), dedicado ao tema de 
hipertexto, escrito em 1988 (14), na véspera da introdução da teia mundial. Hipertexto já era amplamente 
usado na época, mas nada naquele número permite antever a explosão da teia. Talvez o ingrediente 
mais importante da teia, que está faltando naquele documento, seja a introdução do paradigma 
cliente/servidor num ambiente de hipertexto. O cliente 
(<i>browser</i>) especializa-se em obter e apresentar 
páginas, enquanto o servidor especializa-se em montar e disponibilizar as páginas na rede. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 6. Compartilhamento de canal </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Um aspecto que está tendo tremendo impacto no uso das redes é o enorme grau de 
compartilhamento entre milhares ou milhões de usuários de canais digitais de comunicação através da técnica 
chamada de comutação de pacotes (<i>packet 
switching</i>). A idéia básica é quebrar longas mensagens em 
pedaços pequenos que são tratados independentemente e de maneira assíncrona. Isso permite a imediata 
liberação de um canal de comunicação por um usuário que não o esteja usando, muito embora o canal 
esteja à sua inteira disposição em caso de necessidade. Assim, os diversos usuários utilizam o mesmo 
canal de comunicação permitindo que os períodos de inatividade de uns sejam aproveitados por 
outros usuários. Essa técnica facilita também a interatividade da comunicação. Por outro lado, no caso 
de congestionamento do canal, todos os usuários do mesmo estão igualmente prejudicados e a 
experiência mostra que eles absorvem coletivamente o incômodo já que as demoras causadas pelo 
congestionamento são igualmente distribuídas entre os usuários. Essa situação facilita a adaptação de toda 
a comunidade às situações de sobrecarga de tráfego nas linhas, uma vez que a demora na obtenção 
dos serviços requisitados causa automaticamente a diminuição da demanda de comunicação. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 7. Cooperação </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A rede, com os seus mecanismos de comunicação já bem desenvolvidos, revelou-se um 
catalisador e mesmo um instrumento insuperável para a cooperação entre pessoas e grupos trabalhando em 
um objetivo comum, bem definido, a ponto de surpreender até mesmo os maiores especialistas da 
área. Existem milhares de exemplos desse fenômeno, mas talvez o caso mais dramático seja aquele 
do desenvolvimento cooperativo do sistema operacional Linux. 
</p><p align="JUSTIFY">O Linux é um entre os inúmeros sistemas operacionais da família Unix. Ele está sendo 
desenvolvido desde 1991 através da Internet por milhares de ativistas, geralmente entre 20 e 30 anos de idade, que, 
via de regra, não se conhecem pessoalmente (15). Acreditamos que 
<i>qualquer</i> especialista que fosse chamado a opinar em 1990 sobre a possibilidade de sucesso de uma operação de tamanha complexidade, 
desenvolvida por uma equipe tão numerosa e tão heterogênea, sem laços de comunicação face a face, 
concluiria pela mais absoluta impossibilidade de sucesso da tarefa. Pois bem, o Linux roda de forma estável 
desde 1993. Além disso, ele é totalmente gratuito e distribuído como 
<i>software</i> livre, isto é, junto com o 
seu programa fonte, que pode ser alterado conforme os interesses ou necessidades de cada usuário. 
</p><p align="JUSTIFY">Desenvolvido inicialmente para a plataforma PC, literalmente disponível em qualquer esquina, o
Linux hoje conta também com implementações para as arquiteturas da família 68000 da 
Motorola, Alpha da Digital e Sparc da SUN. Ele está começando a ser usado também em arquiteturas 
muito complexas na área da supercomputação. Implementações para os microprocessadores PowerPC e 
MIPS estão em andamento e bem adiantadas. Várias dessas implementações têm o apoio explícito das 
empresas envolvidas nas respectivas arquiteturas (Digital, NEC e IBM), em que pese o fato de estas 
empresas possuírem o seu próprio sabor de Unix em que investiram já milhões de dólares. 
</p><p align="JUSTIFY">Por outro lado o Unix é, sem dúvida, um sistema operacional de uso amplo, muito desenvolvido 
e versátil, tanto que é o único que está implementado na quase totalidade dos tipos de 
computadores. Entretanto, ele foi bastante prejudicado pela falta de uma normatização ampla, o que levou a 
uma dispersão das características do sistema, pois cada fabricante tentou seguir as suas próprias idiossincrasias. 
</p><p align="JUSTIFY">Por esses fatos todos, consideramos hoje em dia o Linux como o único sistema com 
possibilidades concretas de alcançar o 
<i>status</i> de <i>padrão de fato</i> da família Unix. Note-se que, se não houvesse 
microcomputadores ou rede Internet, certamente não haveria Linux! 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 8. Informação distribuída </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Como no caso da computação distribuída, a rede abriu a possibilidade de armazenamento 
distribuído da informação. Isto é, existe agora a possibilidade de 
se guardarem informações similares e 
de mesma natureza em locais distintos. Um servidor especializado disponibilizará os dados para 
quem deles precise, numa arquitetura cliente/servidor. É necessário dizer que a realização desse 
paradigma ainda está muito aquém das suas possibilidades e que grandes avanços podem ser esperados 
nesse campo. Os exemplos que existem são simples mas impressionantes pelo potencial que 
oferecem. Vamos dar apenas dois exemplos. 
</p><p align="JUSTIFY">Nosso primeiro exemplo é a própria teia mundial, pois o conjunto total de páginas pode ser 
visto como um único banco de dados de informações, uma espécie de enciclopédia totalmente 
descentralizada, sem nenhum tipo de coordenação além da sintaxe comum para a apresentação da informação. 
Uma situação dessas dá a impressão, à primeira vista, de uma anarquia total, na qual a localização de 
uma agulha específica num palheiro tão descoordenado seria absolutamente impossível. Difícil se 
enganar mais! Não levou mais do que um ou dois anos para que surgissem novas ferramentas, adaptadas 
ao ambiente da rede, que resolvessem essas questões de forma brilhante, tornando a localização da 
informação um simples exercício. Temos em mente os indexadores, como o sistema de índices Alta 
Vista (16) descrito na subseção 4.6 deste documento. 
</p><p align="JUSTIFY">Apesar do sucesso dos indexadores, existem ainda inúmeros problemas a serem resolvidos 
no sentido de aprimorar e agilizar a localização das informações na teia. Os indexadores existentes 
baseiam-se em critérios sintáticos e freqüentemente oferecem um universo muito numeroso de soluções, 
sem poder ordená-las segundo sua relevância para o pesquisador. Isso pode dificultar a localização ágil 
da informação procurada (17). 
</p><p align="JUSTIFY">O segundo exemplo é um banco de dados de informações muito simples, quase sem estrutura, e 
cujo controle seria absolutamente impossível centralizar. Trata-se do conjunto de nomes de recursos 
computacionais espalhados pela Internet. Isso é usado em todas as comunicações da rede, em particular 
no endereçamento de mensagens de 
<i>e-mail</i>. De fato, o conjunto de nomes e endereços na rede local 
do Instituto de Matemática e Estatística da USP nada tem a ver, e nada deve ter a ver, com o conjunto 
de nomes e endereços na rede local da Reitoria da Universidade de Paris. E esse banco de dados 
distribuídos, chamado de Domain Name System, está montado de tal forma que esses dados, embora 
administrados e constantemente atualizados de forma totalmente descoordenada, podem ser igualmente 
usados pela totalidade de agentes computacionais ligados à Internet. 
</p><p align="JUSTIFY">Ainda assim, é importante observar que a montagem de um banco de dados distribuídos que 
reflita a estrutura de uma grande organização ainda é de uma dificuldade proibitiva. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3. 9. Normatização e sistemas abertos </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A área da informática é caracterizada historicamente pelo surgimento de padrões de fato para onde
 converge a maioria, se não a totalidade, dos usuários dentro de um segmento homogêneo. As 
técnicas concorrentes com o padrão de fato, por melhores que possam eventualmente ser, estão condenadas 
à morte, às vezes instantânea, às vezes lenta e sofrida. Existem inúmeros exemplos, tanto em 
<i>hardware</i> quanto em <i>software</i>, desse processo. 
</p><p align="JUSTIFY">Os padrões de fato podem ser públicos ou proprietários. Nos casos de padrões proprietários 
tornarem-se o padrão de fato, como é o caso da família Windows de sistemas operacionais da Microsoft, 
é garantia de vendas praticamente sem concorrência. Existem também casos de empresas que 
desenvolvem um conjunto de normas referentes a uma dada tecnologia e tornam essas normas públicas. 
A publicação das normas diminui muito a vantagem comercial da empresa mas aumenta muito a 
predisposição do público pela sua adoção. As empresas SUN e Netscape utilizam bastante esse 
expediente (NFS, Java, SSL, etc.). 
</p><p align="JUSTIFY">No caso da Internet, as suas normas e protocolos são públicos se fixados após amplas consultas 
a toda a comunidade. Trata-se de uma seqüência de documentos chamados Request for Comments 
(RFC) que podem ser encontrados na teia (18). A primeira RFC é datada de 4 de julho de 1969 e, em 2 
de fevereiro de 1997, a mais recente tem o número 2092. 
Existe um complexo mecanismo que normatiza a própria edição da seqüência RFC e que determina também o processo de padronização (19), 
isto é, como e quando uma RFC vira um padrão (STD). Existem hoje aproximadamente 50 padrões 
nas séries STD. Os padrões são periodicamente revistos e atualizados, tudo dentro da séries 
RFC. Dessa forma os padrões são amplamente divulgados após a sua filtragem por uma 
comunidade numerosa. Tudo isso facilita sobremaneira a adoção universal dessas normas. 
</p><p align="JUSTIFY">É preciso observar que qualquer processo de padronização é muito complexo e existem 
muitos riscos de o padrão não ser finalmente adotado. Se o padrão for fixado muito cedo, corre-se o risco 
de ficar obsoleto prematuramente, penalizando os que o adotaram. Se o padrão for fixado muito 
tarde, corre-se o risco de não ser seguido por já existirem outros mecanismos satisfatórios em 
funcionamento cuja desativação seria inconveniente. Por esses motivos, além de interesses comerciais evidentes, 
há muitos padrões que viram letra-morta, às vezes antes mesmo de serem publicados. Um exemplo é 
o modelo ISO-OSI para redes de computadores que, embora muito bonito conceitualmente, em 
pouco tempo virou uma peça apenas literária diante da força da adoção maciça da Internet, que não o 
seguiu por ser anterior a ele (20). 
</p><p align="JUSTIFY">Felizmente, o mecanismo RFC encontrado pela Internet possibilitou um mecanismo ágil e 
eficiente de padronização que, até agora, permitiu as readaptações que a rede exige devido aos 
freqüentes avanços tecnológicos e também ao volume crescente de adesões. Isso foi e está sendo essencial 
para o bom funcionamento da rede pelo mundo afora, principalmente quando atentamos para a 
extraordinária rapidez com que a rede se desenvolve. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>3.10. Crescimento exponencial </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">As funções exponenciais são caracterizadas pelo fato de que ao longo do tempo seus 
valores dobram, no caso de exponenciais crescentes, ou diminuem para a metade, no caso de 
exponenciais decrescentes, num intervalo de tempo constante independente do valor da função num 
determinado instante (21). 
</p><p align="JUSTIFY">Funções exponenciais decrescentes ocorrem freqüentemente na natureza. Talvez o exemplo 
mais conhecido seja a variação da intensidade de radioatividade de um material radioativo. Esses 
materiais são caracterizados pela sua meia-vida, o que nada mais é do que o intervalo de tempo em que 
diminui para a metade a intensidade radioativa daquele material. 
</p><p align="JUSTIFY">Funções exponenciais crescentes são muito raras na natureza e quando ocorrem duram um 
tempo limitado, em geral curto, pois na natureza os recursos disponíveis são sempre limitados. Como 
as funções exponenciais crescentes têm um crescimento muito acentuado, o valor da função 
rapidamente excede o limite imposto pelos recursos disponíveis. 
</p><p align="JUSTIFY">As áreas da computação e da comunicação parecem desafiar essa afirmativa. De fato, elas vêm 
se caracterizando, já há década, por uma sucessão de fenômenos exponenciais crescentes com 
constantes de tempo de duplicação que variam entre alguns meses até poucos anos. Talvez o processo exponencial
 mais longo de que se tem notícia na natureza se refira ao crescimento do poder computacional 
disponível por US$ 1. Esse parâmetro vem seguindo uma exponencial crescente de constante de tempo de 
aproximadamente 18 meses que vem sendo observada desde o lançamento dos primeiros computadores 
comerciais em meados da década de 1950. Ou seja, desde essa época, decorridos 40 anos, houve uma 
duplicação do poder computacional disponível por um dólar 27 vezes seguidas, ou seja, uma variação de 134 
milhões de vezes em 40 anos. Estes números são aproximados pois não conhecemos um estudo preciso 
nessa direção nos termos descritos. Tal estudo, por sinal, pode ser bastante complicado pois não está claro 
como medir o poder computacional de um sistema computacional complexo que tem muitos componentes, 
cada um dos quais sujeito a sua própria lei exponencial de desenvolvimento. De qualquer forma, os 
números apresentados oferecem uma indicação geralmente aceita como 
precisa. 
</p><p align="JUSTIFY">Uma outra lei similar é conhecida como lei de Moore. Trata-se de Gordon Moore, um 
dos fundadores da Intel, maior fabricante mundial de circuitos integrados. Ele enunciou a sua lei 
em 1965, numa época em que um microchip podia integrar algo como quatro transistores: "o 
desempenho de microchips produzidos em massa vai dobrar a cada 18 meses" (22). Nota-se que 
o limitante de preço nesse caso é substituído pela condição de produção em massa, o que dá 
um efeito similar, já que só é possível produzir em massa componentes suficientemente 
baratos para poderem ser absorvidos pelo mercado. Por outro lado, a própria produção em massa 
acaba barateando esses componentes. Todos esses fenômenos são observados na área da 
computação. A <i>figura 1 </i>dá suporte à lei de Moore. 
</p><p align="JUSTIFY">Outra quantidade que vem seguindo uma lei exponencial crescente é a largura de banda 
disponível para consumo amplo em linhas de transmissão digital. Este processo exponencial começou mais 
tarde do que o processo do aumento do poder computacional, mesmo porque durante os 15 primeiros 
anos de existência comercial dos computadores não havia, do ponto de vista de transmissão de 
dados, nenhum interesse nessas linhas. O processo, porém, vem se acelerando muito nos últimos 
anos, principalmente com o advento da fibra óptica. Há previsões de que o crescimento desse 
processo ultrapassará, e  muito, o crescimento do poder computacional (23).
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>Figura 1(Crescimento da capacidade de memória disponível por US$: ela dobra a cada 20 meses)</b>

<br><br>
</p><center>
<img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/figura1.jpg">
</center>
<br><br>
<p align="JUSTIFY">
</p><p align="JUSTIFY">Observamos que não se espera uma interrupção desses fenômenos nos próximos 15 a 20 anos, 
ou melhor, não se conhecem, neste momento, barreiras científicas ou tecnológicas que impossibilitem 
a continuação do processo de evolução tecnológica exponencial da área de informática ou de 
telecomunicações nesse período (24). Dessa forma, não está descartada a possibilidade de uma nova melhora 
da ordem de 1.000 vezes, nos próximos 15 a 20 anos, na capacidade de processamento de 
computadores. O progresso poderá ser mais dramático ainda nas capacidades de transmissão dos canais de 
comunicação. De fato, não estão descartadas velocidades de 25 Tbps (25 trilhões de bites por segundo) num futuro 
não muito distante. Esses ganhos, se concretizados, mais uma vez mudarão completamente o perfil global 
da área em direções que são absolutamente imprevisíveis neste momento. Como será o mundo em que 
cada mesa terá um computador que hoje valeria US$ 2.000.000,00, comunicando-se com velocidades 
um milhão de vezes maiores do que as atuais? Que 
<i>software</i> rodará em tal ambiente? 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>Figura 2(Crescimento da rede Internet: ela dobra a cada 15 meses)</b>
<br><br>
</p><center>
<img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/figura2.jpg">
</center>
<br><br>

<p align="JUSTIFY">
</p><p align="JUSTIFY">A título de exemplificar o processo exponencial de crescimento incluímos três gráficos. No 
primeiro, mostramos a evolução dos preços de seis pastilhas de memória. Os preços são ajustados para o 
valor do dólar americano em 1977 e os dados foram extraídos do livro de Hennessy e Patterson (25). 
No segundo, mostramos a evolução do número de computadores ligados na Internet, com dados 
extraídos de várias fontes (26). Dos dados da 
<i>figura 2</i> concluímos que desde a sua fundação, 27 anos atrás, 
o número de computadores na Arpanet/Internet dobra a cada 15 meses, aproximadamente. Mantido 
esse ritmo de crescimento, a Internet terá tantos computadores quantos serão os habitantes do planeta 
Terra no ano de 2011. Será que chegaremos lá? Em mais 15 anos apenas? O terceiro gráfico, cujos dados 
são provenientes de duas fontes (27), mostra a espantosa evolução do número de servidores da teia mun
dial. Este é o mais recente fenômeno da Internet e constitui o processo exponencial mais rápido de 
que se tem notícia no presente contexto. A 
<i>figura 3</i> ilustra o processo, mostrando que o número de 
servidores da teia dobra a cada 14 semanas, desde o seu advento em 1993. Esse crescimento 
extremamente rápido é provocado pela adoção quase instantânea da nova tecnologia pela Internet já existente. 
É provável que passado o período de adoção inicial o crescimento da teia passe a acompanhar o 
crescimento da Internet. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>Figura 3(Número de servidores da teia mundial WWW: ele dobra a cada 14 semanas)</b>
<br><br>
</p><center>
<img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/figura3.jpg">
</center>
<br><br>

<p align="JUSTIFY">
</p><p align="JUSTIFY">Como se vê, o crescimento exponencial está na base de qualquer entendimento do passado e 
do futuro da área da informática. Mas é muito difícil raciocinar com processos exponenciais 
crescentes. A primeira constatação que conhecemos do crescimento exponencial da capacidade computacional 
foi feita por John von Neumann (28). Acreditamos, porém, que em 1957, época da sua morte, nem 
mesmo von Neumann tivesse a visão do que viria em seguida. Uma consideração muito mais precisa 
do crescimento exponencial, incluindo previsões para um futuro distante, encontra-se no livro de 
Licklider (29) sobre a "biblioteca do futuro", escrito em 1964. Uma das previsões mais impressionantes sobre 
o desenvolvimento da informática encontra-se nesse livro e está citado na íntegra na subseção 6.11 
deste trabalho. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4. Aspectos Históricos</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Do ponto de vista físico, redes de computadores se compõem de computadores e de ligações 
entre eles. A rede pode necessitar de outros elementos ativos, além dos computadores propriamente ditos, 
que são computadores especializados no tratamento dos dados que trafegam pela rede. Um 
componente essencial para qualquer rede é o conjunto de 
<i>software</i> que realiza tanto os serviços disponíveis na 
rede, visíveis para o usuário, quanto os serviços de comunicação entre os computadores, em geral 
invisíveis para o usuário final. Assim, é apropriado começar a história das redes com algumas palavras sobre 
a história dos computadores. O leitor interessado encontrará muito mais informações na literatura 
especializada (30). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.1. Computadores </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">O primeiro computador digital, o Eniac, foi inaugurado em fevereiro de 1946, cinqüenta anos 
atrás, construído na Universidade da Pensilvânia durante a Segunda Guerra Mundial, dentro de um 
programa do exército americano que procurava automatizar o cálculo de tabelas balísticas. Imediatamente 
se reconheceu a utilidade universal do invento e passou-se à construção de modelos com mais 
memória interna que incorporavam o conceito de programa armazenado, fundamental para a utilização 
prática da máquina. Até os primeiros anos da década de 1950 várias máquinas foram construídas. Elas 
eram todas diferentes e todas artesanais, mas todas seguiam a chamada arquitetura 
von Neumann, delineada nos primeiros trabalhos sobre a construção de computadores digitais (31). Nos meados da década 
de 1950 começou a produção dos primeiros computadores comercialmente disponíveis. A IBM saiu 
na frente nesse processo, o que lhe valeu o domínio quase absoluto do mercado de informática até 
meados da década de 1980 e um papel predominante até hoje. 
</p><p align="JUSTIFY">Até 1960 todos os computadores eram baseados em válvulas nos dez anos seguintes temos o 
predomínio de computadores transistorizados. A partir de 1970 aumenta o uso de circuitos integrados e 
por volta de 1978 inicia-se a era dos computadores baseados em microprocessadores que dominam 
o mercado até hoje, após um desenvolvimento espetacular dessa tecnologia nos últimos trinta anos. 
É interessante destacar aqui o papel fundamental da pesquisa em Física da Matéria Condensada, 
uma aplicação da Mecânica Quântica, no desenvolvimento dos semicondutores utilizados nos 
circuitos integrados, baseados em silício, um material barato e abundante na natureza. 
</p><p align="JUSTIFY">Com a miniaturização do 
<i>hardware</i> veio o barateamento dos computadores e a conseqüente 
disseminação dos mesmos. Inquestionavelmente um marco nesse processo foi a introdução do computador
pessoal, que se consolidou definitivamente num curto espaço de cinco ou seis anos a partir do 
seu lançamento, em 1977, pela Apple. Outro marco foi a introdução das estações de trabalho por volta 
de 1983, sendo que a tendência atual é a fusão entre a estação de trabalho e o computador pessoal, tal 
é o aumento de capacidade do último e a diminuição dos preços da primeira. Estima-se que existem 
hoje entre cem milhões e duzentos milhões de computadores em operação. 
</p><p align="JUSTIFY">Até 1980 a computação era basicamente centralizada dentro de cada organização com a 
ocorrência, a partir dos anos 70, de grandes sistemas de terminais "burros" (isto é, sem capacidade de 
processamento local) ligados num grande e "poderoso" computador central. Isso aliviava o desconforto da 
concentração dos equipamentos e permitia um acesso mais espalhado a eles. A solução deixava a 
desejar, porém, devido a dificuldades de gerenciamento e de escalabilidade do sistema e à falta de 
possibilidades de personalização do ambiente computacional de cada usuário. 
</p><p align="JUSTIFY">Durante a primeira metade dos anos 80 começa uma tendência de proliferação de 
computadores pessoais isolados e de estações de trabalho interconectadas em redes locais para responder à 
demanda computacional. Com a possibilidade de alocar o computador perto do usuário e cada vez mais em 
seu próprio ambiente de trabalho, aumenta a demanda por poder computacional e cada vez mais 
tarefas passam a ser feitas com a intervenção do computador. Nessa época o computador pessoal 
autônomo começa a apresentar limitações devido ao seu isolamento e à dificuldade de gerenciamento de 
grande número de equipamentos muito parecidos que exigiam atenção individual. Isso leva à popularização 
de redes locais de microcomputadores por volta de 1990. 
</p><p align="JUSTIFY">Em ambientes desenvolvidos, hoje em dia, o computador pessoal é integrado numa rede local com 
vários servidores dos mais diferentes serviços (em geral os servidores são estações de trabalho ou 
computadores de alto desempenho). Essa rede local está conectada à rede mundial Internet, fazendo com que 
quaisquer dois computadores na Internet possam trocar informações em grandes quantidades e com grande 
eficiência. Nessa realidade não é raro que uma pessoa use o seu terminal durante várias horas por dia para as 
finalidades mais diversas possíveis. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.2. A Arpanet </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A idéia da construção de uma rede de computadores que pudesse trocar informações surgiu 
na Advanced Research Projects Agency (Arpa) do Departamento de Defesa dos EUA quando, em 
1962, a Agência contratou J. C. R. Licklider (32) para liderar as suas novas iniciativas através do 
Information Processing Techniques Office (IPTO) da Agência. Um dos sonhos de Licklider era uma rede 
de computadores que permitisse o trabalho cooperativo em grupos, mesmo que fossem integrados 
por pessoas geograficamente distantes, além de permitir o compartilhamento de recursos escassos, 
como, por exemplo, o supercomputador ILLIAC IV, em construção na Universidade de Illinois, com 
o patrocínio da própria Arpa. O projeto foi amadurecendo e adquiriu momento quando a Arpa 
contratou Lawrence Roberts (33), do Lincoln Lab do MIT, em 1967, para tornar a idéia uma realidade. 
Nessa mesma época Licklider, tendo saído da Arpa em 1964, assumiu a direção do Projeto MAC no MIT. 
</p><p align="JUSTIFY">Foi escolhido para a rede um modelo proposto por Paul Baran (34), que lançou a idéia de 
comunicação digital via comutação de pacotes numa série de estudos sigilosos feitos na RAND 
Corporation. Esses estudos foram realizados em função de um contrato com a Arpa cujo objetivo era a 
idealização de um sistema de comunicações que não pudesse ser interrompido por avarias locais. Nessa época 
a guerra fria estava no seu auge e a preocupação dos militares americanos era uma rede de 
telecomunicações que não possuísse uma central e que não pudesse ser destruída por nenhum ataque 
localizado. Uma conseqüência importante dessa escolha e dos desenvolvimentos posteriores é que a rede 
Internet herdou essa propriedade. Na verdade, qualquer defeito de equipamentos na rede não apenas 
não interrompe o seu funcionamento como adicionalmente nem chega a interromper sequer as 
comunicações entre processos em curso na hora da avaria, desde que permaneça em funcionamento 
alguma conexão física entre os dois processos. Isso resulta na robustez extraordinária da rede Internet. 
</p><p align="JUSTIFY">Para realizar o primeiro experimento com a rede foram escolhidas quatro universidades que 
seriam conectadas em janeiro de 1970 na rede computacional Arpanet. Eram elas a Universidade da 
Califórnia em Los Angeles (centro do desenvolvimento do 
<i>software</i>), o Stanford Research Institute, a Universi
dade da Califórnia em Santa Bárbara e a Universidade de Utah, todos beneficiários de contratos 
com a Arpa. Além da comunidade acadêmica, a rede original atendia também à comunidade militar 
americana. A rede se expandiu rapidamente, incluindo computadores de variadas plataformas de 
<i>hardware</i> e de <i>software</i>, demonstrando que a comunicação e a cooperação entre sistemas até mesmo de 
concepções muito diferentes eram perfeitamente factíveis. Havia treze computadores na rede em janeiro 
de 1971, 23 em abril de 1972 e 38 em janeiro de 1973. Foi organizada a primeira demonstração 
pública da rede em 1972 por ocasião da "First International Conference of Computer Communications", 
realizada no outono de 1972. Nessa oportunidade a rede já dava suporte a um amplo conjunto de 
serviços regulares, entre os quais estavam incluídos o 
<i>login</i> remoto e o correio eletrônico, cujo volume de 
uso surpreendeu os próprios responsáveis pela rede. Ou seja, a rede estava se revelando, desde os 
seus primórdios, como um instrumento muito efetivo de cooperação. 
</p><p align="JUSTIFY">As ligações da Arpanet usavam linhas telefônicas dedicadas à velocidade de 56 Kbps. Seus 
elementos ativos, chamados de Interface Message Processors (IMP), eram constituídos de 
computadores comercialmente disponíveis, cuidadosamente escolhidos para essa finalidade. Outro aspecto 
relevante é que a execução do projeto foi confiada a empresas particulares entre as quais deve ser mencionada 
a BBN (Bolt, Beranek, and Newman Inc.), de Cambridge, Mass., que era a principal executora. 
</p><p align="JUSTIFY">É curioso notar que as empresas de telecomunicações devotaram, por muito tempo, um 
amplo pessimismo à técnica de comutação de pacotes, conforme relatado num artigo do principal 
realizador da rede Arpanet, Lawrence G. Roberts (35). Faz pouco tempo apenas que esse pessimismo foi 
trocado por uma participação ativa nas redes de computadores, mas mesmo hoje os serviços dessas 
empresas, do ponto de vista das redes de computadores, deixam muito a desejar. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.3. A CSnet</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">O sucesso da Arpanet se propagou rapidamente a outras comunidades, que não possuíam 
contratos com o DoD (Department of Defense), mas desejavam participar da nova era das comunicações. 
Assim nasceu a CSnet, uma rede computacional relativamente barata que interligou todos os 
departamentos de Ciência da Computação dos EUA. A idéia nasceu em 1979 (36) sob a liderança de 
Lawrence Landweber da Universidade de Wisconsin, atual presidente da Internet Society. A CSnet teve 
amplo apoio e participação ativa da Arpa e da National Science Foundation, NSF. 
</p><p align="JUSTIFY">Rapidamente forjou-se uma união dos departamentos interessados, elaborou-se uma arquitetura 
na qual as ligações da rede seriam realizadas através de serviços públicos de comutação de pacotes 
(Telenet e Phonenet) e estabeleceu-se uma lista de serviços de rede, pobre em relação à Arpanet, que 
era constituída basicamente de correio eletrônico e de transferência de arquivos. Procurou-se aproveitar 
ao máximo a experiência e o 
<i>software</i> já existente na Arpanet, sendo a comunicação entre as duas 
redes um dos objetivos básicos da experiência. A NSF acompanhou de perto o planejamento da rede e 
acabou se tornando o seu principal financiador por um período prefixado, após o que as universidades 
participantes teriam que assumir os custos. A NSF tomou mesmo uma medida inédita em relação a 
financiamento de quaisquer outras pesquisas: assumiu a administração centralizada do projeto por um 
período de dois anos para garantir que a experiência não falhasse por falta de uma coordenação central neutra. 
</p><p align="JUSTIFY">O projeto foi definitivamente aprovado pela NSF em janeiro de 1981 e tornou-se operacional 
em julho de 1982. A CSnet foi um dos marcos da história das redes computacionais, pois serviu 
para estabelecer várias novidades que viriam a influenciar o desenvolvimento da área: 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">· o conjunto da Arpanet e da CSnet constituiu-se na primeira rede heterogênea e pode ser 
considerado o precursor da Internet; 
</p><p align="JUSTIFY">· o experimento, sendo desenvolvido no seio dos grupos de pesquisa em computação, contou com 
a cooperação da comunidade mais bem preparada para propor e implementar novos serviços, como 
um diretório único de pessoas da comunidade, novas extensões da rede, etc.; 
</p><p align="JUSTIFY">· o experimento testemunhou o grau de adesão entusiástica de uma comunidade inteira, de 
alguns milhares de membros, alargando substancialmente os seus hábitos de comunicação, o que resultou 
num novo patamar de cooperação, levando a alguns resultados inimagináveis até então, como o estabeleci
mento de protocolos comuns de comunicação e o significativo nível de aproveitamento de 
<i>software</i> por grupos amplos, usando plataformas de 
<i>hardware</i> e <i>software</i> diferentes; 
</p><p align="JUSTIFY">· o experimento foi instrumental no envolvimento da NSF no financiamento e administração de 
redes computacionais, serviu também para que a NSF pudesse acompanhar de perto o papel da rede na 
vida de uma comunidade científica. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Todos esses aspectos foram pioneiros e acabaram levando à constituição, logo mais, da Internet 
e da NSFnet, marcos obrigatórios para se chegar à situação atual. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.4. A Usenet</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A terceira rede que merece menção nesta retrospectiva histórica é a chamada Usenet, por 
suas características únicas. Trata-se de uma rede que obteve o maior número de participantes nos 
anos pioneiros, sem contar com nenhum tipo de subsídio centralizado. Era baseada numa arquitetura 
muito simples, sem precisar da comutação de pacotes, mas muito fácil de ser realizada. Oferecia apenas 
os serviços mais simples como correio eletrônico e transferência de arquivos. A rede levou ao 
estabelecimento de um novo serviço, o News ou a conferência mundial, que se tornou muito popular e que 
existe até hoje. 
</p><p align="JUSTIFY">A Usenet era baseada no programa uucp (Unix to Unix copy) que vinha incluído em todos 
os sistemas Unix, cuja popularidade crescia exponencialmente nessa época. Esse programa nada mais 
é do que a cópia de arquivos entre sistemas remotos. As ligações eram feitas por linha discada, 
usando <i>modems </i>de 300 a 2400 bps, em horários predeterminados, quando dois computadores trocavam as 
suas informações. Para se conectar à rede tudo que era necessário era um computador rodando Unix 
com acesso a um <i>modem</i>, uma linha discada e de um amigo ou organização dispostos a servir de 
ponto intermediário de comunicação. Assim, a rede cresceu de forma absolutamente descentralizada, 
anárquica mesmo, chegando a centenas de milhares de usuários em 1986 (37). Essa rede iniciou-se por 
volta de 1978 e posteriormente a arquitetura foi aproveitada para formar uma das primeiras redes 
européias, a Eunet. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.5. Nascimento da Internet </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Três fatos muito importantes devem ser mencionados neste ponto. De um lado temos 
a implementação de toda a pilha de protocolos TCP/IP da Arpanet, na versão do Unix escrito 
em Berkeley, a "Berkeley System 
Distribution" (BSD). Este sistema era distribuído gratuitamente 
para universidades e rodava na arquitetura Vax da Digital, a mais popular em universidades na 
época. Posteriormente ela deu origem a SunOS, também muito popular em ambientes acadêmicos, 
ligados às redes então existentes. A inclusão desse 
<i>software</i> num sistema operacional de ampla 
distribuição foi um fato catalisador que levou ao estabelecimento do TCP/IP como um padrão de fato. O 
sucesso desse padrão forçou a adesão da Microsoft em 1995, e a partir daí a inclusão desta pilha de 
protocolos em sistemas operacionais é praticamente obrigatória, sob pena de alto risco de falência do 
empreendimento. 
</p><p align="JUSTIFY">O segundo fato que merece menção é o surgimento da empresa SUN que aproveitou os 
projetos da Stanford University Network e que foi fundada por entusiastas de grande visão da 
Universidade de Stanford e da Universidade de Berkeley, em 1982. A SUN popularizou o sistema 
operacional Unix, versão BSD, e facilitou sobremaneira a utilização de computadores em redes locais 
baseadas nos protocolos TCP/IP. Essa política fazia parte da filosofia da empresa, que professava nos anos 
80 que <i>"the Network is the 
computer"</i> numa espécie de reformulação do lema "a união faz a força". 
Um dos instrumentos mais poderosos da empresa nesse sentido foi a introdução do Network File 
System (NFS), baseado num protocolo que a empresa tornou público e que teve uma aceitação 
universal logo em seguida. A NFS permite o compartilhameto transparente dos discos de vários 
computadores numa rede local facilitando a visão da rede heterogênea como um único sistema pelo usuário. 
</p><p align="JUSTIFY">O terceiro fato a ser mencionado é a criação, em 1984, de outra empresa, a Cisco, por gente que
 igualmente saiu da Universidade de Stanford. Essa empresa escolheu como missão a fabricação 
de elementos ativos para a rede Internet, isto é, computadores especializados que tratam do 
encaminhamento, pela rede, dos pacotes digitais. Os mais complexos desses equipamentos são os roteadores 
que substituíram os computadores especializados originais, chamados de Interface Message 
Processors (IMP). A fabricação de 
<i>hardware</i> especializado para o protocolo TCP/IP tem duas 
conseqüências importantes. Por um lado, ele aumenta muito a eficiência do processo de roteamento dos 
pacotes, permitindo que a rede alcance patamares de eficiência substanciais. 
Por outro lado, a fabricação em grande escala implica num barateamento dos equipamentos. Tudo isso transformou a Cisco 
numa empresa gigante que fatura quatro bilhões de dólares por ano e a Internet numa rede que conta 
hoje (julho de 1997) com mais de dezesseis milhões de computadores. 
</p><p align="JUSTIFY">Nos anos intermediários da década de 1980 houve uma proliferação de redes (38) tais como 
Decnet, Vnet, Bitnet, Hepnet, Janet, Junet, Earn, Netnorth, Fidonet, etc. O livro de Frey e Adams (39), 
editado em 1989, listava nada menos do que 105 redes espalhadas pelo mundo todo, várias delas com uma 
forma particular de endereçamento de 
<i>e-mail</i>. 
</p><p align="JUSTIFY">Nessa época a rede Arpanet começou a mostrar sinais de fadiga devido à baixa velocidade de 
suas linhas (56 Kbps). Dado o enorme interesse, agora de toda a comunidade acadêmica, na conexão à 
rede, a NSF iniciou em 1987 um investimento maciço no estabelecimento de uma ampla rede acadêmica 
de alta velocidade e que interligasse inclusive os seus centros de supercomputação com toda a 
comunidade consumidora desse recurso. Criou-se a rede acadêmica NSFnet que viria a absorver a Arpanet, 
desativada em 1990. Nessa época a NSFnet alcançava toda a comunidade acadêmica dos EUA com um 
<i>backbone</i> de velocidade 1,5 Mbps. A NSFnet, sendo uma rede acadêmica, regia-se por uma Acceptable 
Use Policy que definia os usos aceitáveis e inaceitáveis da rede. A rede, sendo financiada pela NSF, 
não podia ser usada para fins lucrativos. Vale mencionar que a NSF executou e operou a sua rede 
através de empresas privadas, sendo a empresa Merit,  ligada à Universidade de Michigan, uma das 
principais contratadas. Maiores detalhes sobre a história da NSFnet podem ser encontrados em Frazer (40). 
</p><p align="JUSTIFY">Com a proliferação das redes, o modelo e protocolos TCP/IP emergiram como o padrão 
predominante da área e isso tornou muito fácil a interligação de redes independentes. A megarrede 
resultante chamou-se de Internet, que nasceu sem alardes como um corolário natural da Arpanet e da NSFnet 
(41). A Internet até hoje não tem um órgão regulamentador oficial. O que existe, desde 1992, é a 
Internet Society, uma sociedade civil que talvez assuma o gerenciamento global da rede em algum momento 
no futuro. A situação atual lembra talvez a anarquia da Usenet nos anos 80, descrita pouco acima. 
</p><p align="JUSTIFY">Apesar dessa situação, o que mantém a Internet como uma unidade é o protocolo TCP/IP e 
o mecanismo público de fixação de suas normas através dos chamados RFC (Request for 
Comments), cuja aderência rigorosa é forçada pelo desconforto, que se manifestaria em dificuldade de 
comunicação com o resto do mundo, de quem queira, porventura, se afastar. Em outras palavras, o volume da 
Internet no momento é tal que se torna impossível qualquer tentativa de concorrência com ela. É 
impossível exagerar, com relação a esse aspecto, a importância da adoção do protocolo TCP/IP pela NSFnet 
em 1987. A própria indústria de 
<i>hardware</i> incorporou esse protocolo nos seus produtos e, hoje em dia, 
a montagem de uma rede computacional fora dos padrões TCP/IP provavelmente seria proibitiva 
em função do seu alto custo e baixa probabilidade de aceitação. Como conseqüência dessa situação 
as muitas redes que existiam ainda cinco anos atrás vêm desaparecendo uma a uma, sendo absorvidas 
pela Internet. Todas as tecnologias proprietárias encaixam-se nessa descrição. 
</p><p align="JUSTIFY">A ampla disponibilidade de 
<i>hardware</i> TCP/IP relativamente barato e a ampla disponibilidade 
do <i>software</i> de rede TCP/IP, praticamente gratuito, levam ao estabelecimento cada vez mais numeroso 
de redes corporativas, sem interesse de conexão à rede Internet, por questões de segurança 
empresarial, que usam a mesma tecnologia, o mesmo 
<i>hardware</i> e o mesmo <i>software</i> da Internet. Essas redes, 
que estão revolucionando a vida interna das grandes empresas (42), vêm sendo chamadas de Intranets 
desde o início de 1996 (43).
</p><p align="JUSTIFY"> A NSF percebeu que a rede construída excedia rapidamente o seu interesse e o seu potencial 
de financiamento e que, vencida a fase de introdução, a rede poderia se manter em seus próprios 
pés. Assim, em 1994, ela anunciou que se retiraria em 1995 do financiamento da rede NSFnet e 
que concomitantemente iria desistir da imposição da Acceptable Use Policy. A rede estava aberta para a
 exploração comercial e para o uso com fins lucrativos. Foi previsto um período de alguns meses 
para a transição. Esta transição veio a ser conhecida como a "privatização" da Internet. 
</p><p align="JUSTIFY">A resposta da comunidade mundial foi imediata, explosiva e até surpreendente. O uso da 
rede aumentou para patamares nunca antes imaginados e continua crescendo no seu ritmo exponencial. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.6. Nascimento da teia mundial</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Até pouco mais de três anos atrás os aplicativos principais da rede Internet eram o correio 
eletrônico, o serviço de News, o 
<i>login</i> remoto em qualquer máquina da rede e a transferência de 
arquivos. Tudo isso mudou com o aparecimento e popularização da World Wide Web, a partir de 1994. Essa 
teia mundial entrou com um crescimento exponencial de velocidade nunca antes visto, nem mesmo na 
área da computação, e hoje domina, com facilidade, as outras aplicações que, aliás, foram todas 
incorporadas a ela. A utilização dos paradigmas de hipertexto, multimídia, arquitetura cliente/servidor e 
comunicação segura, aliados a uma interface agradável e lúdica, fácil de ser aprendida e usada, e 
aliados também a uma enorme facilidade de disponibilização de informações na teia, revolucionou a 
própria revolução da "sociedade da informação". 
</p><p align="JUSTIFY">Os dois nomes mais associados ao fenômeno da teia são o do físico suíço Tim Berners-Lee, 
que liderou a partir de 1990 a implantação da WWW nos laboratórios da Cern em Genebra, Suíça (44), 
e do então estudante de computação Marc Andreessen que, no laboratório de supercomputação 
da Universidade de Illinois, desenvolveu o visor 
(<i>browser</i>) Mosaic em 1993, levando a um novo 
patamar a facilidade e versatilidade de uso do sistema. Em 1994 Andreessen deixou a universidade para ser 
um dos fundadores da empresa Netscape, que hoje domina o mercado de 
<i>software</i> dos aplicativos para a Internet com um conjunto de produtos liderados pelo visor que herdou e desenvolveu as 
propriedades e funcionalidades do Mosaic. Outra característica desse visor é que ele é disponível para 
praticamente todas as plataformas de 
<i>hardware</i> e de <i>software,</i> e assim ele transforma o computador numa 
verdadeira máquina Netscape com uma interface de uso independente da plataforma utilizada. Isso contribui 
ainda mais para a universalização dessa interface. 
</p><p align="JUSTIFY">Outro fenômeno que faz jus à menção neste histórico é o surgimento do sistema de indexação 
Alta Vista (45) em dezembro de 1995. Ele memoriza a parte pública da teia, através da visitação 
periódica de todas as páginas atingíveis por um robô (31 milhões de páginas em julho de 1997, localizadas 
em 627.000 servidores), e efetiva uma indexação muito engenhosa e eficiente do material levantado. 
A partir desses dados um computador localizado nos 
laboratórios da Digital em Palo Alto 
responde instantaneamente a mais de 31 milhões de perguntas diárias (360 perguntas a cada segundo, dia e 
noite), vindas do mundo inteiro. 
</p><p align="JUSTIFY">Uma pergunta típica seria qual o conjunto de páginas da teia mundial que contêm as palavras 
"Tom Jobim" uma perto da outra. A resposta instantânea chega como uma lista de tantos apontadores, 
quantas páginas encontradas (490, no caso), cada uma trazendo o título, o endereço e as primeiras palavras 
da página referenciada. Com um clique do 
<i>mouse</i> acessa-se a página propriamente dita, qualquer que 
seja a sua localização no globo terrestre. Em outras palavras, o Alta Vista instantaneamente coloca a 
teia inteira na ponta dos dedos de qualquer um que saiba fazer uma pergunta adequada e bem 
formulada. Não é necessário dizer que o serviço foi um sucesso instantâneo. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>4.7. História das redes no Brasil </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">À guisa de epílogo, adicionamos alguns dados sobre a história das redes no Brasil. A nosso ver 
o responsável pioneiro pelo rápido progresso inicial das redes no Brasil foi o professor Oscar Sala, 
da Universidade de São Paulo, único ex-presidente tanto da Sociedade Brasileira para o Progresso 
da Ciência quanto da Academia Brasileira de Ciências. Ele fez chegar ao Brasil a rede Bitnet em fins 
de 1988, conectando a Fapesp ao Fermilab nos EUA, através de uma linha dedicada de velocidade 
4.800 bps, alugada da Embratel. Nessa linha coexistiram várias outras redes também, como a Hepnet, 
a Decnet, a Usenet e finalmente a própria Internet. 
</p><p align="JUSTIFY">Na época, o professor Sala era o presidente do Conselho Superior da Fapesp e, nessa qualidade, ele
 foi instrumental para interessar aquela Fundação em dar um apoio decisivo às redes e um incentivo 
a toda a comunidade acadêmica do país na adoção desse recurso. Isso foi feito através do 
financiamento da ligação das instituições acadêmicas paulistas à rede ANSP (Academic Network at São Paulo) 
e através da facilitação da ligação à rede de outras instituições acadêmicas no país, franqueando a 
todos o uso acadêmico da linha internacional mantida pela Fapesp. Essa postura da Fapesp levou a uma 
rápida e entusiástica adoção da nova cultura em especial nas três universidades paulistas que, por sua 
vez, começaram a investir na disponibilização dos recursos às suas respectivas comunidades. 
</p><p align="JUSTIFY">A ligação da Fapesp não foi a primeira conexão de rede a chegar ao Brasil. Ela foi precedida 
pelo Laboratório Nacional de Computação Científica do CNPq que alugou uma linha da Embratel três 
meses antes da Fapesp, ligando-se à Bitnet. Mas essa linha, embora muito importante, não teve o 
mesmo impacto da iniciativa da Fapesp. A ligação do LNCC não evoluiu com o tempo e foi desativada com 
a mesma velocidade inicial de 9.600 bps, em 1996, quando da desativação da rede Bitnet no Brasil. 
</p><p align="JUSTIFY">Outra ligação pioneira que deve ser mencionada é aquela realizada pela rede Alternex, ligada 
ao Ibase, uma organização não-governamental que se ligou à rede Usenet, via linha discada 
internacional, em julho de 1989. 
</p><p align="JUSTIFY">Em retrospecto, o evento de maior relevância para o Brasil foi a nossa ligação à Internet. A 
primeira ligação nacional em TCP/IP foi realizada pela Fapesp em fevereiro de 1991. A Fapesp 
conseguiu disponibilizar o TCP/IP no seu Vax, e se encarregou da administração do domínio br e da 
distribuição dos números IP em todo o país, áreas em que colabora com o Comitê Gestor da Internet/BR até hoje. 
</p><p align="JUSTIFY">Alguns meses depois, ainda em 1991, estabelece-se outra linha internacional, ligando o Rio 
de Janeiro à Internet, com origem no Núcleo de Computação Eletrônica da UFRJ. Essas ligações 
pioneiras foram instrumentais para a aceitação do padrão TCP/IP no Brasil. Na verdade, nessa época, era 
objeto de discussão ativa o protocolo que seria mais adequado para ligar o Brasil nas redes internacionais. 
</p><p align="JUSTIFY">Deve ser mencionada também a dificuldade substancial que todos tiveram para interessar a 
Embratel nessas primeiras ligações internacionais. Uma outra dificuldade era causada pela política de reserva 
de mercado, vigente na época. Essa política dificultava o acesso brasileiro ao sistema operacional Unix 
e às estações de trabalho que se revelaram, 
<i>a posteriori</i>, como os meios mais ágeis de viabilizar 
e disseminar a cultura Internet no país. Vale a pena registrar que a quase totalidade da nossa 
comunidade teve o seu primeiro contato com o Unix a partir de 1990, quando se iniciou o relaxamento da 
reserva de mercado, sendo bastante raros os casos de estações de trabalho, quase sempre solitárias e 
compartilhadas por comunidades numerosas, operando em 1988 ou 1989. 
</p><p align="JUSTIFY">O CNPq se interessou pelas redes computacionais a partir de julho de 1989, quando foi lançada 
a Rede Nacional de Pesquisas (RNP) na feira da Sucesu, sem estrutura física própria na época. O 
<i>backbone</i> nacional da RNP começou a ser instalado em 1991, com linhas de 9.600 bps. Hoje, as linhas 
principais da RNP têm velocidade de 2 Mbps. Até agosto de 1996 a ligação da RNP ao exterior era feita 
através das linhas mantidas pela Fapesp; nessa data a RNP obteve uma linha própria que ligava o 
Distrito Federal aos EUA. 
</p><p align="JUSTIFY">Com a posse do governo Fernando Henrique Cardoso, em 1995, estabeleceu-se o Comitê Gestor 
da rede Internet no Brasil, com a atribuição de coordenar e incentivar a implantação dessa rede no 
país. Paralelamente, a RNP decidiu tornar-se uma rede mista que, além do tráfego acadêmico, 
carregava também tráfego comercial. Assim, ela passou a constituir a espinha dorsal da rede Internet no 
Brasil. Até hoje, o <i>backbone</i> da RNP é o único de alcance nacional no país. Ele foi e continua sendo 
instrumental para o acentuado progresso da Internet no Brasil. Maiores informações sobre a situação e evolução 
da Internet no Brasil podem ser encontradas no servidor do Comitê Gestor (46). 
</p><p align="JUSTIFY">Deve ser destacada também a espiral de Campos (47), uma contribuição de Ivan Moura Campos 
à conceituação do desenvolvimento da Internet em espirais. Isso compreende ciclos que se iniciam 
em pesquisa e desenvolvimento, passam por parcerias governamentais e depois por parcerias privadas 
para chegar como uma <i>commodity</i> à sociedade, antes de recomeçar o próximo ciclo. 


</p><p align="JUSTIFY">Se nos basearmos no que é possível entrever hoje, fica claro que o impacto da revolução 
informática em todos os aspectos da atividade humana tem o potencial de ser muito grande e de provocar 
mudanças muito profundas. Entretanto, em uma situação de mudanças rápidas e muitas vezes 
imprevisíveis, como a que vivemos hoje, é extremamente difícil determinar a natureza exata e detalhada do 
impacto da entrada em uso das novas tecnologias sobre cada aspecto dessas atividades. Nessa situação 
é inevitável que existam controvérsias sobre o futuro da área (48). 
</p><p align="JUSTIFY">Apesar de o computador pessoal já existir há anos, sendo hoje, pelo menos nos países mais 
desenvolvidos, um eletrodoméstico como qualquer outro, a introdução do outro elemento crucial do 
sistema, a rede mundial Internet, no sentido da sua abertura para uso fora do meio acadêmico, ocorrida 
há apenas dois anos, é muito recente e interage fortemente com o primeiro, de forma que não se pode 
dizer que as conseqüências da introdução das novas tecnologias de computação e comunicação já 
tenham se desenvolvido e estabelecido completamente (49). 
</p><p align="JUSTIFY">No meio acadêmico a disponibilidade tanto de computadores poderosos quanto de 
redes computacionais significativas precede em vários anos sua disponibilidade pela sociedade em geral. 
De fato, o meio acadêmico foi o berço original de ambos esses universos tecnológicos. Entretanto, 
mesmo no meio acadêmico o impacto dessas tecnologias ainda está longe de sua realização completa, 
e existem alguns aspectos cuja introdução ainda é muito recente, mesmo nesse caso. 
</p><p align="JUSTIFY">Devemos ter em mente que as reações sociais e culturais à introdução de tecnologias 
completamente novas como essas têm velocidade limitada pelas características e ritmos biológicos e 
psicológicos do ser humano. De forma muito grosseira, para a adaptação a fenômenos como a 
revolução informática, a qual envolve mudanças significativas na educação do indivíduo, pode-se 
avaliar que o tempo de resposta típico seja da ordem do tempo do ciclo de educação do indivíduo, ou 
seja, cerca de uma e meia a duas décadas. No meio acadêmico, no qual a curiosidade e a 
flexibilidade intelectual são requisitos básicos, esse tempo deverá ser mais curto, mas mesmo assim não 
menor do que alguns anos. 
</p><p align="JUSTIFY">Estamos hoje na desconfortável situação de nos encontrar, surpreendentemente, bem no meio 
deste complexo e inesperado processo e, apesar de sua magnitude e suas formidáveis potencialidades 
serem claramente aparentes, estamos talvez excessivamente envolvidos para poder ver com clareza e, 
muito menos, prever o que se seguirá com qualquer tipo de segurança. 
</p><p align="JUSTIFY">Assim, o que podemos fazer com alguma segurança é listar as mais notáveis características da 
nova tecnologia e apontar os possíveis impactos que poderão ter, chamando a atenção, sempre que 
possível, para os indícios já existentes de sua realização. Procuraremos nortear nossa avaliação dos 
impactos por meio da informação disponível sobre os impactos que já estão razoavelmente bem 
caracterizados no meio acadêmico. Entretanto, deve-se manter em mente que os impactos sobre a sociedade em 
geral poderão ser quantitativa e qualitativamente diferentes destes. 
</p><p align="JUSTIFY">Resumindo os aspectos técnicos principais, a rede computacional internacional, com seus 
protocolos universais abertos e extremamente flexíveis, aliada à existência de microcomputadores 
poderosos nas pontas de cada ramificação capilar, uma vez que a rede esteja completamente 
capilarizada, alcançando a casa de qualquer cidadão que queira utilizar seus serviços, constitui um meio de 
comunicação completamente novo. Este novo instrumento da civilização apresenta inacreditável 
eficiência no compartilhamento dos meios de comunicação, efetivamente zera as distâncias entre os 
habitantes do planeta e permite o acesso, a transmissão e a replicação exata de quantidades praticamente 
ilimitadas de informação, que são mantidas de forma distribuída por toda a rede, podendo entretanto 
ser indexadas e relacionadas, através da própria rede, para facilidade de localização. Ademais, o 
novo instrumento, devido à sua eficiência e à facilidade de comunicação que permite, é um 
catalisador efetivo na cooperação entre entes, mesmo que distantes; uma realidade impossível de ser 
alcançada antes do seu advento. 
</p><p align="JUSTIFY">Qual a relação entre isso tudo e o desenvolvimento do país? A importância da ciência em geral 
e também da revolução da informática para o desenvolvimento tem dois aspectos principais: a 
mudança de fatores econômicos e a mudança da cultura e das mentes das pessoas que a compõem. A 
revolução informática tem amplo potencial para mudar de forma profunda esses aspectos. Essas 
mudanças básicas, por sua vez, tornam inevitáveis mudanças sociais, políticas e legais a elas relacionadas. 

<b>5.1. Preliminares 
acadêmicos</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Começamos por mencionar alguns impactos das novas tecnologias no meio acadêmico. 
</p><p align="JUSTIFY">Um dos primeiros efeitos da tecnologia foi a viabilização de cooperação científica a distância de 
uma forma muita mais efetiva. Basta o correio eletrônico para que seja possível desenvolver trabalhos 
em cooperação através da rede entre pesquisadores que já se conheçam pessoalmente e que possam 
esporadicamente se reencontrar. O ritmo de desenvolvimento pode cair um pouco se os 
pesquisadores estiverem em fusos horários diferentes, e também devido à necessidade de se digitalizar todas 
as conversas, argumentos e discussões técnicas. Entretanto, apesar desses desconfortos, passar a ser 
possível na prática trabalhar dessa forma, e assim alguns trabalhos são feitos, que de outra forma talvez 
não fosse possível. A transmissão de vozes e vídeo pela rede poderá ter um impacto ainda maior, 
permitindo que o processo de implantação desse estilo de trabalho avance muito mais, por tornar o trabalho 
mais confortável.
</p><p align="JUSTIFY">Outro impacto do correio eletrônico é a submissão eletrônica de trabalhos para publicação, o que 
já está sendo feito de forma rotineira por uma grande quantidade de revistas especializadas. Isso 
tem levado ao surgimento de revistas especializadas completamente eletrônicas, que prescindem 
completamente da publicação em papel. De fato, cessa a necessidade de publicação em papel como 
verdadeira forma de disseminar o resultado de pesquisas, e de outras formas de informação nas quais o que 
interessa é mais a velocidade de acesso à informação e não tanto a longevidade do registro permanente 
da informação. Isso está forçando uma revisão do conceito de publicação científica (50). 
</p><p align="JUSTIFY">Um aspecto no qual a WWW tem um grande potencial de impacto é a publicação pela rede 
de dados dos mais variados tipos. Nos grandes experimentos, está se tornando rotina a 
disponibilização de acesso não apenas ao resultado de uma ou outra análise dos dados, mas aos dados na íntegra, 
em formato digital, acessíveis para análise por qualquer um que tenha acesso à rede. Também se 
pode citar nessa categoria a colocação de acervos de museus científicos em bancos de dados acessíveis 
pela rede, incluindo, por exemplo, dados e fotos de espécimes biológicos. Esses bancos facilitam a 
preparação de viagens de estudos, com acesso preliminar às espécimes ou dados, e podem 
mesmo substituí-las, em alguns casos. Há também a disseminação de resultados de programas 
para modelamentos de variados tipos, por exemplo, de dinâmica atmosférica, que são de interesse 
mais geral e não puramente para a pesquisa. 
</p><p align="JUSTIFY">Um impacto importante da revolução informática nas ciências naturais, que contribui muito para 
o desenvolvimento destas, é aquele proporcionado pela computação especializada de alto 
desempenho, e pelo aumento exponencial do desempenho dos sistemas computacionais em geral. Ele tende a 
ocorrer num prazo menos imediato, mas pode ser muito profundo. Algumas áreas na qual ele é importante 
são a física de sistemas complexos, a biologia e bioquímica do DNA e a química computacional. 
</p><p align="JUSTIFY">A revolução do microcomputador, acoplada com a revolução das redes, está começando a se 
fazer sentir mesmo no mundo especializado dos computadores de desempenho extremamente alto. Os 
grandes e caríssimos supercomputadores de outrora, fabricados especificamente para esse fim, estão 
começando a ser substituídos por redes de microcomputadores extremamente rápidos interligados por 
redes de pequena extensão e velocidade extremamente alta, da ordem de Gbps. 
</p><p align="JUSTIFY">Hoje, a CPU do mais rápido supercomputador existente não chega a ser três vezes mais veloz do 
que o mais rápido microprocessador produzido em massa (51), enquanto a velocidade das redes 
especializadas de pequena extensão utilizadas para interligar as memórias desse microprocessador, com 
velocidades acima de 1 Gbps, já representa uma fração apreciável da velocidade de comunicação 
interna entre o processador e a sua memória. 
</p><p align="JUSTIFY">Assim, não é tão surpreendente que computadores paralelos formados por redes rápidas com 
um grande número de microprocessadores possam alcançar e até mesmo superar o desempenho 
dos supercomputadores tradicionais. De fato, a máquina mais rápida em funcionamento hoje é um 
computador construído pela Intel para o governo norte-americano, que é constituído de mais de 
7.000 processadores Pentium, como os que podemos ter em casa em um computador pessoal. 
</p><p align="JUSTIFY">O impacto da revolução da informática nas atividades de pesquisa do mundo acadêmico se acopla
a outro impacto profundo e de prazo longo, o impacto sobre a educação. Apesar de já serem 
usados computadores em rede para fins educativos em muitos lugares, ainda é cedo para avaliar este 
impacto no mundo acadêmico, pois um dos fatores mais importantes para isso deverá ser a WWW, 
cuja introdução é muito recente. De fato, os ventos mais fortes de mudança vêm dos jovens, e nem 
tanto de seus professores. São os jovens que estão mais envolvidos na revolução, tanto como 
realizadores das façanhas técnicas quanto como vetores das novas tecnologias. Talvez seja necessário 
esperar pela nova geração de professores, que chegue ao mercado de trabalho já completamente 
informatizada, para que o impacto na educação se faça sentir com força total. 
</p><p align="JUSTIFY">Concluímos comentando sobre o papel das universidades, que até agora têm atuado tanto 
como inventoras e formadoras da cultura quanto como as maiores consumidoras das novas tecnologias, 
nesta revolução. A tecnologia que propulsiona a revolução é recente, foi desenvolvida nas últimas 
décadas. Tanto o projeto quanto a construção contaram com grande contribuição da comunidade 
acadêmica. Talvez a maior contribuição das universidades tenha sido a de serem os usuários-cobaia do 
sistema, estabelecendo novos paradigmas para o uso do recurso. 
</p><p align="JUSTIFY">Tratando-se de uma comunidade ávida por novidades em geral e sem medo de explorar o 
desconhecido, o desenvolvimento desses paradigmas foi muito rápido, e possivelmente profundo, e 
resultou um conjunto de tecnologias de 
<i>hardware</i> e <i>software</i> muito fácil de ser usado e assimilado pela 
sociedade em geral, processo este que está em curso desde 1994 quando da permissão da 
comercialização da rede, que operava com fortes restrições de acesso até aquele momento. Os novos paradigmas 
de armazenamento, troca e compartilhamento da informação são capazes de mudar hábitos muito 
básicos, como por exemplo o funcionamento de editoras e jornais, o advento do 
<i>home-banking</i>, o advento da biblioteca digital, o advento da educação a distância, a possibilidade de operar serviços de 
telefonia através da Internet e a distribuição de 
<i>software</i>. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>5.2. Aspectos culturais</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Uma das formas de se analisar a extensão da influência de uma nova tecnologia sobre a cultura 
da sociedade é através de sua influência visível na linguagem falada por esta sociedade. Existe a 
possibilidade de que a Internet venha a ter um papel importante no estabelecimento de uma língua 
universal no planeta terra, provavelmente alguma forma de inglês. Hoje é comum que jovens 
universitários, apesar de não falarem essa língua, sejam capazes de ler e escrever razoavelmente bem nela, devido 
ao seu contato constante com a rede. Com a disponibilização de forma rotineira da transmissão de 
serviços de telefonia de áudio e vídeo pela rede, além da linguagem escrita, é possível que a capacidade 
de entender e falar a língua venha a se adicionar a estas num futuro próximo. 
</p><p align="JUSTIFY">Uma provável tendência que a rede mundial poderá ter, e que talvez deva ser encarada mais 
como um perigo, é a tendência para a monocultura. Em termos da influência cultural da rede, os 
ventos sopram muito definitivamente dos países do Primeiro Mundo, em particular dos EUA. Poderá 
acontecer uma excessiva homogeneização das culturas dos muitos povos diferentes que participam do 
que costumamos chamar de civilização ocidental? Ou mesmo da cultura de todos os povos que 
tiverem acesso amplo a esse novo aspecto do ambiente do planeta? 
</p><p align="JUSTIFY">Isso poderia ter conseqüências muito sérias, em primeiro lugar porque pode dar origem a 
reações violentas, mas não menos porque a perda da capacidade da espécie de experimentar com 
culturas diferentes é uma perda de diversidade que, assim como a perda de diversidade biológica em 
ecossistemas, pode levar a processos degenerativos e eventualmente à extinção. Temos bons motivos para temer 
essa possibilidade, entretanto se a aceitarmos como provável poderemos estar dando ao ser humano 
menos crédito do que ele merece. É perfeitamente possível que as culturas mudem e se adaptem ao 
novo ambiente, sem contudo desaparecer. É até possível que novas culturas acabem emergindo 
como resultado desse processo. Mas o debate, por ora, fica necessariamente aberto sobre se a introdução 
das novas tecnologias irá, a longo prazo, empobrecer ou enriquecer a civilização que conhecemos hoje. 
</p><p align="JUSTIFY">De qualquer forma é inevitável que estejamos desenvolvendo uma visão do futuro segundo a 
qual estamos caminhando a passos largos para o estabelecimento de uma "sociedade da informação" 
no terceiro milênio. Essa ampliação do escopo daquilo que foi desenvolvido no meio acadêmico pode
 levar à perda ou atenuação da tradição de cooperação e liberdade de informação que caracterizou 
o início da Internet: só o futuro poderá esclarecer essa questão. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>5.3. Aspectos econômicos</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A informática moderna tem um papel óbvio na produção industrial, que já é importante há 
algum tempo. Como um exemplo claro disso, podemos citar os sistemas de CAD (Computer Aided 
Design) e CAM (Computer Aided Manufacturing), que são amplamente utilizados na indústria. O impacto 
da informática sobre os meios produtivos é, portanto, mais imediato e também potencialmente 
mais doloroso, obrigando a sociedade a adaptações rápidas, como, por exemplo, o caso do deslocamento 
de mão-de-obra industrial pela produção robotizada através de CAM. Entretanto, não é só na indústria 
que a informática pode ter um impacto econômico considerável. Sua importância é grande também 
na agricultura, por exemplo para a previsão de tempo, uma atividade na qual tanto a rede de 
comunicação quanto a computação de alto desempenho são de importância capital. 
</p><p align="JUSTIFY">O uso amplo de meios informáticos na indústria, tanto diretamente na produção quanto na 
administração, é tão importante que pode ser caracterizado como uma nova revolução industrial. As 
novas tecnologias permitem uma automação inteligente de processos, passível de controle fino por meio 
de programação. Com a rede internacional e a WWW, passam também a estar disponíveis novas 
formas de propaganda e de pesquisa de mercado, muito mais eficientes e flexíveis que as atuais, que 
podem ter um grande impacto sobre o sistema produtivo. A produção automatizada e a comunicação e 
cooperação das empresas produtoras com o público de consumidores, através da nova rede 
internacional, combinam-se para dar origem a possibilidades verdadeiramente fantásticas. 
</p><p align="JUSTIFY">Por um lado, a produção automatizada permite não só a produção em massa de bens, como 
também um maior grau de personalização e variedade dos produtos, pois não é mais necessário retreinar 
um corpo de trabalhadores quando se muda o item a ser produzido, nem é mais necessário reconstruir 
uma linha e metodologia de produção. Todas essas mudanças passam agora a se realizar no âmbito de 
um programa de computador, e a administração da produção passa a ser um problema de programação. 
É concebível que as fábricas possam ser completamente representadas por programas que simulem 
sua ação, e que a criação e o teste de programas para a produção de novos produtos possam ser 
realizados por meio de tais simulações. 
</p><p align="JUSTIFY">Por outro lado, os consumidores podem agora realizar as compras através da rede, utilizando 
a WWW, e pelo mesmo processo podem suprir os fornecedores de informação detalhada sobre 
suas preferências. Com o aparecimento de 
<i>shopping</i> pela WWW, podemos fazer supermercado sem sair 
de casa, simplesmente clicando o <i>mouse</i> em produtos ao longo das prateleiras de um supermercado 
virtual, ao mesmo tempo em que podemos obter informação detalhada sobre cada produto (52). 
</p><p align="JUSTIFY">O <i>feedback</i> produzido pelas próprias aquisições realizadas e por mensagens enviadas pelos 
consumidores, que podem agora ser monitorados em detalhe, pode ter um efeito muito mais imediato sobre 
a produção e distribuição de muitos produtos. Em alguns casos, quando o conteúdo do produto 
adquirido é algum tipo apropriado de informação, a própria entrega dos produtos pode ser feita imediatamente 
por <i>down-loading</i> através da rede, como, por exemplo, no caso de 
<i>software</i>, livros em forma eletrônica, gravações musicais e gravações de vídeo. 
</p><p align="JUSTIFY">As novas tecnologias de computação e comunicação e os novos métodos de manipulação de 
informação a que eles dão origem têm o potencial de mudar de forma profunda as sistemáticas de 
produção e distribuição de produtos ora existentes. Ao mesmo tempo, eles têm o potencial de provocar 
instabilidade social, pelo menos durante algum tempo, por exemplo pelo alijamento de mão-de-obra de 
nível educacional mais baixo, e devido à necessidade de retreinamento de funcionários e mesmo dos 
consumidores. 
</p><p align="JUSTIFY">Por outro lado, o próprio funcionamento da rede é um negócio de bilhões de dólares anuais 
envolvendo empresas de telecomunicações, provedores de acesso, especialistas em projeto de páginas, 
etc., gerando novas necessidades no mercado de trabalho. Um exemplo seria a nova profissão de 
"minerador de informações", um especialista que pudesse localizar na rede informações sobre um tema 
específico e pudesse editá-las e reorganizá-las para posterior utilização por um cliente. 
</p><p align="JUSTIFY">Um aspecto econômico interessante é a questão de quem arca com os custos da própria Internet. Até
 agora, como se tratava de uma rede acadêmica voltada para a pesquisa, os custos eram distribuídos 
entre universidades, institutos de pesquisa e agências financiadoras. Como se tratará essa questão em 
uma rede universal pesadamente usada para fins comerciais? Idealmente cada usuário pagará pelo 
seu próprio uso do serviço, mas no momento, não temos tecnologia para contabilizar de forma 
detalhada o uso da rede, e o estabelecimento dessa tecnologia provavelmente exigirá intenso 
investimento. Exigirá também um consenso bastante amplo quanto ao modelo a ser adotado para tal 
contabilidade. Maiores informações podem ser obtidas na própria teia (53). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>5.4. Aspectos sociais e 
políticos</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Quais podem ser as conseqüências da absorção de um objeto completamente novo e tão 
complexo, como este, pela sociedade? Certamente podemos esperar mudanças de comportamento, e o perigo 
de instabilidade causada por mudanças muito rápidas. Entretanto, é muito difícil prever com 
segurança as possíveis conseqüências do processo para  sabermos que cuidados tomar. É argumentável que 
exista um limite mínimo de tempo para a consolidação social de revoluções tecnológicas profundas, 
baseado no tempo típico de mudança das gerações no controle dos assuntos da sociedade, entretanto esta é 
uma mudança que poderá muito bem acontecer muito perto deste limite mínimo. 
</p><p align="JUSTIFY">Algumas das possíveis conseqüências sociais advêm simplesmente das novas possibilidades 
de comunicação e de cooperação que passam a existir. Por exemplo, passa a existir a possibilidade de 
que qualquer indivíduo possa transmitir informação para um número ilimitado de outras pessoas, 
através de <i>broadcasting</i> na rede, a custos muito baixos. Este é um privilégio que até agora só estava ao 
alcance dos indivíduos política ou economicamente poderosos. 
</p><p align="JUSTIFY">Por outro lado, é claramente impossível que todos os participantes sejam ouvidos nestes 
<i>broadcastings</i>, pois isso levaria imediatamente a uma enorme sobrecarga de informação chegando a cada um 
dos ouvintes. Que mecanismos surgirão para definir quem é ou não é de fato ouvido? Como cada 
participante decidirá o que ouvir e o que ignorar dentro da massa de dados que atingirá a todos pela rede, 
seja por <i>brodcasting</i> ou simplesmente pelo imenso volume da informação disponível quando 
requisitada pelo participante, numa constante <i>information 
overload</i>? Será necessário que apareça a figura 
do <i>information manager</i> como uma nova profissão, ou como um novo serviço através da própria rede? 
Até que ponto essas tarefas poderão ser feitas automaticamente, por programas de computador? 
</p><p align="JUSTIFY">Devido ao efeito das novas tecnologias sobre os meios produtivos, haverá uma mudança 
qualitativa e quantitativa na demanda por educação. Hoje em dia, vários setores requerem de seus 
empregados "conhecimentos básicos de informática". Trata-se de um segundo nível de alfabetização, com o 
tempo não será mais suficiente saber ler e escrever. As dificuldades atuais para se dar ensino amplo e 
de qualidade tendem a aumentar à medida que o patamar mínimo de qualidade aceitável sobe. 
</p><p align="JUSTIFY">As mesmas tecnologias que originam esses problemas podem vir a trazer sua solução. 
Novos métodos envolvendo ensino assistido por computador estão sendo tentados e podem vir a 
modificar profundamente o processo educacional. Sendo a educação das novas gerações uma das 
principais atividades de qualquer sociedade civilizada, e também uma das mais custosas e difíceis, 
qualquer impacto positivo que as novas tecnologias possam ter sobre os processos e métodos educacionais é 
de extrema importância. Como a educação sempre se realiza em prazos longos, a transição dos 
velhos métodos para os novos pode se mostrar muito lenta se comparada com o crescimento vertiginoso 
da informatização, e o período de transição pode alienar toda uma geração, com o risco de criar 
uma verdadeira bomba social. Certamente um aspecto importante é o papel das novas tecnologias 
como ferramentas de integração mundial. Com o crescente estabelecimento da aldeia global, já existe 
hoje o desafio aos conceitos de país e nação como unidades essencialmente independentes do ponto de 
vista econômico e comercial. Com as novas tecnologias, a curto prazo o mesmo desafio passará a existir 
do ponto de vista cultural e da língua. É de se esperar que vários governos não se sintam confortáveis 
com esse crescente desafio. Talvez seja necessário que o caráter desses governos mude 
consideravelmente para que os países e nações se adaptem às futuras realidades políticas, sociais e culturais do mundo. 
</p><p align="JUSTIFY">Preocupa, em particular, o processo de transição para o mundo do terceiro milênio, que pode 
ser traumático. É inevitável que a transição aconteça aos poucos, com cada país decidindo por sua vez se
 juntar ou não ao bloco dos profundamente informatizados. Se a decisão for de não se juntar, 
resultará a exclusão na certa, e o país passará a fazer parte de um futuro bloco dos excluídos. Se a decisão 
for por juntar, não há garantia de sucesso na adaptação do país e da nação, internamente e 
externamente, às novas realidades, pois provavelmente será necessário que uma série de problemas sejam 
resolvidos a tempo e adequadamente. Naturalmente, o esforço de cada país para juntar-se a um sistema 
cooperativo global é um tremendo incentivo para que esse sistema dê certo. 
</p><p align="JUSTIFY">O impacto mais imediato das novas tecnologias sobre o desenvolvimento de cada país se 
dá principalmente pelo uso da tecnologia informática já existente nas mais variadas atividades 
econômicas, em particular no que diz respeito aos insumos de 
<i>hardware</i>. Quanto aos insumos de 
<i>software</i>, o mesmo pode ser dito quanto aos 
<i>softwares</i> mais básicos de sistema e de operação do 
<i>hardware</i>, bem como quanto a uma grande quantidade de aplicativos de uso geral. 
Entretanto, o desenvolvimento de <i>software</i> para aplicações específicas e a adaptação do software existente às condições nacionais são 
áreas em que faz sentido investir seriamente. Assim, atitudes isolacionistas como as limitações à 
importação de insumos<i> </i>de<i> 
hardw</i>are, para a proteção de uma única indústria, podem comprometer o 
desenvolvimento de toda a economia do país. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>5.5. Aspectos jurídicos, legais e regulatórios </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Um aspecto interessante nesse caso é a possibilidade do uso da rede para a administração de 
muitos setores do governo e de seu relacionamento com o cidadão. Por exemplo, todas as atividades 
burocráticas que cada cidadão deve executar rotineiramente podem ser realizadas pela rede, com o uso, 
quando necessário, dos sistemas públicos de criptografia que estão disponíveis, para garantir sigilo, 
autorização e identificação. Com isso, mesmo processos de autenticação legal podem, em princípio, 
ser realizados através da rede. 
</p><p align="JUSTIFY">Os aspectos legais associados à rede, tanto no sentido do seu próprio funcionamento quanto do 
seu impacto em outros setores, são extremamente complexos e, na realidade, quase desconhecidos. A 
rede nasceu e se desenvolveu como um sistema completamente descentralizado, caótico e anárquico, já 
se espalhando pelo mundo inteiro, e é extremamente difícil colocá-la, de uma hora para a outra, 
dentro de um sistema legal organizado e completo. Além disso, atualmente não existem instrumentos 
efetivos para a imposição de legislação e o policiamento dos participantes. 
</p><p align="JUSTIFY">Tentativas de normatizar o uso da rede e de legislar sobre as atitudes dos participantes, mesmo 
se apenas no meio acadêmico, têm sido sempre muito limitadas e, mesmo assim, de efeito 
indefinível. Provavelmente será necessário esperar que primeiro se estabeleça uma considerável 
jurisprudência para que se possa estabelecer legislação sólida sobre os assuntos da rede. 
</p><p align="JUSTIFY">Certamente o sistema constituído pela rede e pela disponibilidade geral de 
microcomputadores poderosos tem um grande potencial de impacto em muitos aspectos legais. Por exemplo, existe 
o desafio ao conceito de <i>copyright</i>, pois o sistema permite o transporte e a cópia de grandes volumes 
de informação, a custo essencialmente zero, por qualquer usuário. Como será possível defender o 
sistema de <i>copyright</i> e manter vivo o conceito de propriedade intelectual num ambiente como esse (54)?
</p><p align="JUSTIFY">Alguns aspectos se relacionam com os mecanismos que os governos e as sociedades que 
eles representam usam para implementar censura e controle quanto ao conteúdo da informação que 
é transportada pela rede. Sendo a rede um sistema internacional, quem controlará o que trafega por 
ela? Poderá o governo de um determinado país emitir leis e implementar decretos que, através da 
rede, afetarão outros países? De qualquer forma, é extremamente difícil monitorar e policiar toda a 
informação que trafega na rede, dado o seu grande volume e a volatilidade de sua localização e 
percurso de transporte. Nesse sentido popularizou-se uma frase atribuída a Rich Saltz: 
"<i>The net interprets censorship as damage and routes around 
it</i>". 
</p><p align="JUSTIFY">Uma questão em particular está relacionada com o recente aparecimento de sistemas de 
criptografia muito eficientes, inquebráveis pela tecnologia atual, que estão se tornando de uso muito comum na 
rede (55). Os governos em geral, mesmo os democráticos, tendem a assumir que é seu direito ter a 
capacidade de poder ler qualquer mensagem que seja enviada entre membros de sua população ou 
para dentro e fora do país. Em alguns lugares, como a França, por exemplo, chega a ser proibida a utilização
 pela população de qualquer sistema de criptografia. A nova tecnologia da rede põe essa presunção 
em xeque. 
</p><p align="JUSTIFY">Naturalmente, o desafio é ainda maior para governos autoritários, que insistem em manter 
suas populações em regime de isolamento em relação ao resto do mundo. Por um lado, a tecnologia da 
rede está se tornando cada vez mais importante para o desenvolvimento desses países, e por outro é 
difícil manter uma rede de extensão nacional inteiramente isolada, controlando com rigor o acesso a ela 
para cada elemento da população, em especial se não se pode contar com a completa boa vontade de 
cada um dos envolvidos. Como exemplo, podemos citar a tentativa de criação, na China, de uma 
intranet nacional, ou seja, de uma rede de alcance nacional isolada da Internet. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6. Tendências Atuais da Tecnologia </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">A pesquisa nos mais variados aspectos de computação e telecomunicações é efervescente hoje e 
deve continuar trazendo novidades no mesmo ritmo frenético a que nos acostumamos. Várias linhas 
de desenvolvimento vêm sendo anunciadas pela comunidade acadêmica, indústria e Internet Society. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.1. Reforma de endereços IP: de 4 para 16 bites 
</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Os endereços na Internet são em geral descritos em forma legível como, por exemplo, 
ime.usp.br. Essa forma é, digamos, temperada para consumo humano. Os endereços "oficiais" adotados 
pelo protocolo IP são números de 32 bites, normalmente denotados como quatro números entre 0 e 255 
(por exemplo, 143.107.45.13). Quando o protocolo foi adotado, 32 bites, que permitem endereçar mais 
de um bilhão de pontos, eram mais que suficientes. Entretanto, como a alocação de endereços é feita 
por lotes, observa-se o iminente esgotamento desses endereços. 
</p><p align="JUSTIFY">Para lidar com o grande crescimento da Internet, e com uma série de necessidades técnicas que 
se tornaram claras com a experiência, uma nova versão do protocolo IP foi aprovada, utilizando 
endereços com 128 bites. A transição do padrão corrente IPv4 ao novo (IPv6) deverá levar dez anos; o IPv6 
foi projetado de forma que essa transição possa ser feita suavemente. 
</p><p align="JUSTIFY">Isso parece um aspecto técnico mínimo, mas reflete o amadurecimento da tecnologia de redes: 
o novo protocolo não só acrescenta características ao anterior, como também retira outras que se 
revelaram desnecessárias ou que obsolesceram. O IP original contemplava uma rede de uso limitado, 
militar e acadêmico; o novo tem em vista uma verdadeira rede mundial, com múltiplos usos. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.2. Internet II</b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Não obstante o seu tremendo êxito como empreendimento, e talvez até por essa mesma razão, 
a Internet desviou-se muito das suas finalidades originais, tendo chegado a uma situação bastante 
diferente daquela imaginada por seus idealizadores. De fato, tendo hoje abrangência mundial e 
estando aberta aos interesses comerciais de todo o planeta, ela não mais pode ser vista como um sistema 
de comunicações para uso do governo norte-americano e da comunidade de ensino e pesquisa daquele país. 
</p><p align="JUSTIFY">Considerando que a situação atual apresenta vários aspectos insatisfatórios, referentes à 
eficiência e à capacidade de expansão do sistema e considerando ainda as fortes necessidades de evolução 
desse complexo, um grupo formado por algumas das principais universidades de pesquisa 
norte-americanas, por empresas da indústria de informática que desenvolvem tecnologia de ponta e por agências 
do governo dos Estados Unidos, começou a discutir, há cerca de dezoito meses, o projeto de uma nova 
rede computacional que vem sendo chamada de Internet II, dotada de novas características e que, em 
princípio, terá acesso restrito às entidades participantes do empreendimento. 
</p><p align="JUSTIFY">A Internet II, a segunda geração da Internet, está sendo projetada para dotar a comunidade 
norte-americana de ensino superior e pesquisa de novos modos de colaboração interativa e de ensino 
a distância, para integrar a distribuição de coleções bibliográficas digitais em forma multimídia 
com programas acadêmicos e para facilitar o acesso a facilidades de pesquisa especializadas e muito 
caras, tais como aceleradores de partículas e supercomputadores. Não se destina a substituir a Internet, mas
 sim a adicionar conectividade ao sistema, com acesso seletivo. O novo sistema estará conectado 
ao atual e funcionará como uma melhora para finalidades selecionadas. As novas tecnologias 
empregadas na sua edificação são uma evolução das tecnologias atuais e deverão estabelecer os padrões de 
uma nova infra-estrutura global de comunicações. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.3. Redes totalmente em fibras ópticas</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"> A fibra óptica já é mais barata e confiável do que o fio de cobre para a transmissão de sinais. 
Isso está levando à implementação preferencial em fibra de todas as espinhas dorsais de 
comunicação. Tanto do lado da telefonia quanto da TV a cabo, essa troca ainda não chegou à ponta do 
consumidor. A principal dificuldade está na instalação de novos equipamentos de chaveamento, e não na 
instalação dos cabos. Esse problema é econômico, por se tratar de investimento que ou terá um tempo 
de amortização muito longo ou apresentará uma conta demasiado alta para o consumidor, e que, até 
agora, não tem suscitado muito interesse das companhias telefônicas. É preciso notar, porém, que o 
rápido barateamento dos equipamentos, aliado a planejadas mudanças estruturais muito profundas nas 
empresas de telecomunicações do mundo todo, pode trazer alterações a este cenário a médio prazo. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.4. Comunicação 
<i>versus</i> processamento </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Pelo ritmo de desenvolvimento atual das tecnologias de circuitos e de telecomunicações, o 
crescimento da velocidade de comunicação tende a ultrapassar de longe 
o crescimento da capacidade de computação. O limite teórico da fibra é de 25 Tbps por fibra, suficiente para que uma só 
fibra carregue todas as chamadas telefônicas nos EUA no Dia das Mães. Assim, com uma 
disponibilidade grande de banda, uma série de técnicas, utilizadas atualmente para compactar a informação 
antes de sua transmissão, deixaria de ser interessante. Curiosamente, a dificuldade maior em 
aproveitar essa capacidade de comunicação está no processo relativamente lento de transdução entre 
sinais eletrônicos e ópticos  (56). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.5. Comunicação sem fio</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Qualquer que venha a ser o sucesso da fibra na construção básica da rede, haverá cada vez 
mais a necessidade da conexão com a Internet de unidades móveis. Além disso, certas 
localidades geográficas simplesmente tornam antieconômica a extensão da fibra até elas. Para esses casos 
é necessário a comunicação sem fio (ou sem fibra) (57). Atualmente isso está sendo 
implantado com a ampliação dos serviços de telefonia celular e com cada vez maior cobertura do globo 
por satélites de comunicação. 
</p><p align="JUSTIFY">Em ambos os casos, visa-se a terminais de acesso móveis e com baixa potência. 
Telefones celulares devem se encaminhar a ponto de se permitir que sejam, efetivamente, pontos de 
ligação à Internet. Há que se resolver ainda problemas de banda, confiabilidade e segurança de transmissões. 
</p><p align="JUSTIFY">Já está em uso em vários lugares o GPS (Global Positioning System), sistema para a 
localização precisa, via sinal de satélite, de um veículo em movimento. Isso acoplado a um banco de dados 
no veículo permite a apresentação ao condutor de um mapa com a posição do automóvel ou barco. 
É questão de tempo isso se tornar mais comum, com a incorporação de outras informações 
atualizadas periodicamente via rede, como a existência de congestionamentos, o que permite a elaboração de 
rotas alternativas. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.6. Convergência de meios </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"> Observando os enormes avanços permitidos pela comunicação digital da informação 
podemos concluir que haverá uma tendência cada vez mais forte de fusão de várias tecnologias que 
conhecemos hoje como distintas, tais como telefonia, sistemas de áudio, televisão, computação, redes de 
computadores e serviços de fax, de secretária eletrônica e de mensageria. 
</p><p align="JUSTIFY">Essa perspectiva pressupõe uma capilarização maciça de redes digitais de uso múltiplo (58). 
Em primeiro lugar nessa direção vem o advento do 
<i>modem</i> para cabo, que permite usar a infra-estrutura 
da TV a cabo para conexão de rede. Alternativamente, a tecnologia B-ISDN (Broadband 
Integrated Services Digital Network) (59) poderá também levar à capilarização desejada. Existem até 
pesquisas que pretendem transmitir os sinais da rede Internet através da rede de energia elétrica (60). 
</p><p align="JUSTIFY">Com o uso da rede para transmissão de som os serviços telefônicos usuais deverão ser 
fortemente afetados. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.7. Extensão de aplicações locais à Internet </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Várias aplicações que atualmente só funcionam adequadamente em rede local devem se tornar 
de uso mais amplo à medida que a capacidade da rede aumentar. Alguns exemplos são diagnóstico 
médico, jogos interativos em grupo, reuniões virtuais e ensino a distância. Outras aplicações dependem 
ainda do desenvolvimento adequado de 
<i>software</i> e protocolos adequados, como, por exemplo, 
dinheiro eletrônico. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.8. Distribuição eletrônica de 
<i>software</i></b> 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Desde seu início a rede foi usada para distribuir e desenvolver programas; ao mesmo tempo, o 
canal preferencial de distribuição foi, e continua sendo, o comércio tradicional. À medida que a 
banda passante aumentar e mecanismos confiáveis de comercialização eletrônica se 
solidificarem, a tendência de distribuição via rede deverá aumentar. Isso tem um aspecto muito mais amplo do que 
aquilo que normalmente se entende por indústria de 
<i>software</i>. Atualmente quase todos os 
equipamentos dotados de eletrônica contêm uma grande quantidade 
de<i> software</i>; com a possibilidade (futura) 
de ligarmos a cafeteira ou o automóvel diretamente na rede, esse 
<i>software </i>poderá ser atualizado remotamente, evitando 
<i>recalls</i> no caso de falha. Um instrumento recente objetivando essa amplitude 
de aplicação é a linguagem Java. Seu lançamento foi entusiasticamente acolhido pela indústria e 
ela deverá ser a base para a primeira geração desse tipo de 
uso. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.9. Trabalho cooperativo em grupo</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Embora esta tenha sido uma das motivações originais de Licklider ao idealizar a rede, e 
embora a experiência acumulada nessa direção já seja impressionante, há muito espaço e muita 
necessidade para progresso nessa direção. A concretização de muitas experiências já imaginadas depende 
ainda de progressos significativos nas áreas de 
<i>hardware </i>e principalmente de 
<i>software</i>. As possibilidades chegam a desafiar a mente: ensino a distância, com ênfase na cooperação entre os alunos; 
serviços de suporte técnico, de treinamento e de desenvolvimento de produtos com a cooperação dos 
usuários; sistemas de revisão e de comentários públicos sobre trabalhos científicos, sobre livros (61) ou 
sobre produtos de determinada natureza; sistemas de diagnósticos médicos a distância, com 
cooperação entre especialistas geograficamente distantes entre si; estabelecimento de bibliotecas 
digitais especializadas, com a cooperação dos usuários, etc. 
</p><p align="JUSTIFY">As Intranets, em desenvolvimento nos últimos dois anos, e com o pleno uso das tecnologias 
de comunicação e de cooperação desenvolvidas na Internet, são um exemplo concreto nessa direção, 
já em andamento (62). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.10. Continuação do processo exponencial </b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Tanto pelo lado da computação quanto das telecomunicações há espaço ainda para que o ritmo 
de crescimento exponencial se mantenha. Conforme já comentamos no fim da subseção 3.10, 
pelos próximos 15 a 20 anos ainda há espaço para crescimento, cada qual com melhora da ordem de 
1.000 vezes da capacidade atual. No caso das pastilhas de silício é possível que se chegue aos limites 
físicos dessa tecnologia, mas até lá, provavelmente, novas tecnologias, atualmente nos laboratórios, já estarão

 viabilizadas (63). 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>6.11. Algumas previsões especulativas</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Enquanto as direções já apontadas podem ser consideradas "previsões seguras", por se 
referirem a processos já em andamento, outras previsões um pouco mais especulativas podem ser feitas. Isso 
nos traz à lembrança a frase, atribuída ao grande físico Niels Bohr, "é muito difícil fazer 
previsões, principalmente sobre o futuro". Aliás, nesse campo as previsões se mostraram quase sempre 
muito falhas, em geral por excesso de conservadorismo. Tornaram-se folclóricas declarações de capitães 
da indústria de que "<i>I think there is a world market for maybe five 
computers</i>" (Thomas Watson, presidente da IBM, 1943, reportado por 
<i>Time</i> em 15 de julho de 1996) ou "<i>There is no reason for 
any individual to have a computer in their 
home</i>" (Kenneth Olsen, presidente e fundador da Digital, 
1977, reportado por <i>Newsweek </i>em 27 de janeiro de 1997). 
</p><p align="JUSTIFY">Mesmo no campo altamente especulativo e imaginativo da ficção científica, entre autores que 
se destacavam por seu alto nível de informação sobre o estado corrente da ciência e tecnologia, 
encontramos erros hoje risíveis. Por exemplo, Robert Heinlein, em 
<i>Starman Jones</i> (1953), assume viagens a outros sistemas solares, mas a navegação é feita consultando-se tabelas impressas, cujos 
valores devem, na medida do necessário, ser digitados no painel. Ou Isaac Asimov que, em 
<i>The Last Question</i> (1956), descreve um único grande computador que vai sendo aumentado até formar uma 
camada subterrânea sob todo o planeta. Mesmo entre aqueles que participavam do processo era pouco 
visível uma idéia clara de onde se chegaria. Na revista 
<i>Communications of the ACM</i> (Association for 
Computing Machinery), órgão de divulgação de associação internacional envolvendo tanto a comunidade 
acadêmica quanto a industrial e empresarial, não se encontra nada, na década de 60, que pressinta a 
vertiginosa popularização dos computadores e a idéia de uma rede mundial. Uma notável exceção 
se encontra em trabalho de Licklider (64), do qual extraímos: 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">"<i>Economic criteria tend to be dominant in our society. The economic value of information and 
knowledge is increasing. By the year 2000, information and knowledge may be as important as mobility. We 
are assuming that the average man of that year may make a capital investment in an 'intermedium' 
or 'console' ­ his intellectual Ford or Cadillac ­ comparable to the investment he makes now in 
an automobile, or that he will rent one from a public utility that handles information processing 
as consolidated Edison handles electric power. In business, government, and education, the concept 
of 'desk' may have changed from passive to active: A desk may be primarely a display-and-control 
station in a telecommunication-telecomputation system* ­ and its most vital part may be the cable 
('umbilical cord') that connected, via wall socket, into the procognitive utilitynet. Thus our economic 
assumption is that interaction with information and knowledge will constitute 10 or 20 per cent of the total 
effort of the society, and the rational economic (or social economic) criterion is that the society be 
more productive or more effective with procognitive systems than without. 
</i></p><p align="JUSTIFY"><i>*If a man wishes to get away from it all and think in peaceand quiet, he will have merely to turn 
off the power. However, it may not be economicaly feasible for his employer to pay him at full rate for 
the time he does spend in an unamplified cerebration". </i>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Esse trecho, escrito em 1964, dá uma idéia da extraordinária visão daquele que foi escolhido 
para idealizar o projeto Arpanet. 
</p><p align="JUSTIFY">Sem maiores pretensões, arriscamos mencionar aqui as seguintes possibilidades: 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">· Novos paradigmas de computação. 
</p><p align="JUSTIFY">Todos os computadores construídos até hoje têm uma arquitetura baseada num modelo descrito 
na década de 1940 por John von Neumann. Até o momento, não houve sucesso em nenhum 
modelo alternativo. A construção de computadores Von Neumann, primeiro em válvulas, e agora 
em semicondutores, foi bem-sucedida, mas esbarra em certas limitações físicas que podem ser 
eventualmente atingidas, encerrando o processo de crescimento exponencial. São objetos de pesquisa, no
 presente, modelos diferentes de computação, que deverão ser apoiados em tecnologias 
hoje inexistentes: computação biológica e computação quântica. Por enquanto, essas duas 
propostas estão em estado incipiente, tanto pelo lado teórico quanto pelo tecnológico, mas 
argumentos apriorísticos mostram que, se vingarem, devem aumentar em muito os limites da capacidade 
de computação. 
</p><p align="JUSTIFY">· "Killer applications". 
</p><p align="JUSTIFY">Esse é o nome dado para as aplicações que conseguem evidenciar a vantagem de uma nova 
tecnologia, levando à sua adoção maciça. Talvez a convergência com os meios de entretenimento seja já 
suficiente. Talvez já seja a WWW; foi com os visores gráficos que a Internet se popularizou. Com a 
oferta crescente de banda e capacidade de computação, é muito provável que novas aplicações surjam 
com esse efeito catalisador. Já citamos algumas em vista; dessas, a implementação efetiva de 
dinheiro eletrônico é candidata a ter um impacto mais visível, afetando profundamente as bases do 
sistema econômico. 
</p><p align="JUSTIFY">· Massificação total. 
</p><p align="JUSTIFY">Já é recomendada pela IEEE a colocação de tomadas de rede à base de uma para cada 5 
m<sup>2</sup> numa área de trabalho. Prédios modernos de escritórios já estão sendo construídos com uma tomada de rede 
ao lado de cada tomada elétrica comum. Com o tempo isso deve chegar aos lares, a rede de 
comunicação se tornando algo tão comum e essencial à vida moderna quanto a energia elétrica: possivelmente, 
num futuro não muito distante, cada eletrodoméstico será ligado a ambas as redes. Ou, talvez, bastará 
ligá-los apenas à rede de energia elétrica (65). Com novas interfaces homem-computador ora em 
desenvolvimento, cada indivíduo carregará permanentemente seu próprio instrumento de acesso, seja 
diretamente acoplado ao corpo, seja como parte do vestuário. 
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Para outras previsões especulativas nos restringimos a encaminhar o leitor interessado para a 
conferência ACM 97, realizada em San Jose, CA, entre 3 e 5 de março de 1997. A conferência foi o ponto 
culminante das comemorações dos 50 anos de existência da associação e foi dedicada ao tema "The Next 50 Years 
of Computing". Alguns dos especialistas mais formidáveis da área deram os seus depoimentos que 
foram publicados em livro (66). Alguns números recentes da 
<i>Communications of the ACM</i> trazem entrevistas 
com alguns dos palestrantes (67).
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>7. Epílogo</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Quais os limites da revolução da informação? Não existe nenhum à vista. O que se pode ver é 
que praticamente nenhuma atividade humana sairá incólume da revolução da informática, que promete 
chegar ao seu ápice ao amanhecer do terceiro milênio. A rede Internet e o sistema WWW estão tomando o 
mundo de assalto, depois de uma incursão preliminar muito profunda, se menos barulhenta, do exército 
dos microcomputadores. A combinação desses dois exércitos invasores é potencialmente explosiva. 
Senhores acadêmicos, por mais azul que o céu lhes pareça, apertem os seus cintos!
</p><p align="JUSTIFY"><b>Notas</b>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">(1) "The Death of Distance", in 
<i>The Economist</i>, September 30th, 1995; veja também em 
http://www.economist.com/.
</p><p align="JUSTIFY">"The Internet, the Accidental Superhighway", in 
<i>The Economist</i>, July 1st, 1995; veja também em 
http://www.economist.com/."A World Gone Soft ­ A Survey of the Software Industry", in 
<i>The Economist</i>, May 25th, 1996; veja também em http://www.economist.com/"Technology in Finance, Turning 
Digits in Dollars", in <i>The Economist</i>, October 26th, 1996; veja também em http://www.economist.com/. 
</p><p align="JUSTIFY">(2) R. Kraut, "The Internet@Home", in 
<i>Communications of the ACM</i>, 39 (12), 1996, pp. 32­74.
</p><p align="JUSTIFY">(3) O leitor tecnicamente inclinado pode avaliar esta velocidade através da comparação das três 
edições sucessivas do livro <i>Computer 
Networks</i> de Tanenbaum, datadas de 1981, 1987 e 1996 (NJ, 
Prentice Hall, Englewood Cliffs; NJ, Prentice Hall PTR, Upper Saddle River; e NJ, Prentice Hall, Upper 
Saddle River, respectivamente). A primeira edição não fala de Internet e a segunda não fala nem de fibra 
óptica e nem de <i>hubs</i> para redes locais, só para mencionar alguns dos assuntos correntes da tecnologia 
neste momento
</p><p align="JUSTIFY">(4) D. E. Comer, <i>The Internet 
Book</i>, NJ, Prentice Hall, Englewood Cliffs, 1995. Current Cites. 
http://sunsite.berkeley.edu/CurrentCites.EDUCOM, Publications. 
http://educom.edu/web/pubs/pubHomeFrame.html.<b></b>
NII Scan by National Computer Board, Singapore. 
http://www.ncb.gov.sg/nii/. 
</p><p align="JUSTIFY">(5) D. E. Comer, <i>Computer Networks and 
Internets</i>, NJ, Prentice Hall, Upper Saddle River, 1996. 
</p><p align="JUSTIFY">(6) P. M. Senge, <i>The Fifth Discipline: The Art and Practice of the Learning 
Organization</i>, Doubleday, 1990; L. C. Thurow, 
<i>The Future of Capitalism: How Today's Economic Forces Shape 
Tomorrow's World</i>, William Morrow &amp; Company, 1996. 
</p><p align="JUSTIFY"> (7) Mais precisamente, 1 TB = 
2<sup>10</sup> GB = 2<sup>20</sup> MB = 
2<sup>40</sup> bites. Um bite equivale, aproximadamente, a 
um caracter de texto.
</p><p align="JUSTIFY">(8) A. S. Tanenbaum, <i>Computer 
Networks</i>, op. cit., 1996, p. 83. 
</p><p align="JUSTIFY">(9) Merril M. Flood [5, <i>Information 
Processing</i>, 9, pp. 567-74], 1977.          
</p><p align="JUSTIFY">(10) V. Bush, "As We May Think", in 
<i>Atlantic Monthly</i>, 176 (1), pp. 101-8, July, 1945. 
Reimpresso em CD-Rom: <i>The New Papyrus</i>, Microsoft Press, 1986. Veja também em 
http://ccat.sas.upenn.edu/jod/texts/vannevar.bush.html. 
</p><p align="JUSTIFY">(11) D. C. Engelbart and W. K. English, "A Research Center for Augmenting Human Intellect", in 
A. Press (ed.), <i>Proc. of the 1968 Fall Joint Computer 
Conference</i>, pp. 395-410, 1968; J. B. Smith and 
S. F. Weiss, "An Overview of Hypertext", in 
<i>Communications of the ACM</i>, 31, pp. 816-9, 1988. 
</p><p align="JUSTIFY">(12) T. H. Nelson, "Getting It Out of Our System", in G. Schechter (ed.), 
<i>Information Retrieval: A Critical Review</i>, Thompson Books, Washington, DC, 1967, pp. 191-210.
</p><p align="JUSTIFY">(13) J. von Neumann, <i>The Computer and the Brain, 
</i>New Haven, Yale University Press,  1958. 
</p><p align="JUSTIFY">(14) J. B. Smith and S. F. Weiss, "An Overview of Hypertext", in op. cit., pp. 816-9.  
</p><p align="JUSTIFY">(15) Foi fundamental para a existência do Linux a experiência prévia em cooperação do projeto 
GNU da Free Software Foundation, cujo <i>software 
</i>constitui parte fundamental do sistema operacional Linux. 
</p><p align="JUSTIFY">(16) R. Seltzer, E. J. Ray, and D. S. Ray, 
<i>The AltaVista Search Revolution</i>, Berkeley, Osborne 
McGraw-Hill, 1997.      
</p><p align="JUSTIFY">(17) C. M. Bowman, P. B. Danzig, U. Manber, and M. F. Schwartz, "Scalable Internet 
Resource Discovery: Research Problems and Approaches", in 
<i>Communications of the ACM</i>, 37 (8), 1994, pp. 
98-107, 114; O. Etzioni, "The World-Wide Web: Quagmire or Gold Mine?", in 
<i>Communications of the ACM</i>, 39 (11), 1996, pp. 65-8. 
</p><p align="JUSTIFY">(18) Index of Requests For Comments. http://nic.merit.edu/documents/. 
</p><p align="JUSTIFY">(19) O standard número 1 da Internet. std01-rfc1920. txt (Untitled). 
ftp://nic.merit.edu/documents/std/std01-rfc1920. txt.                     
</p><p align="JUSTIFY">(20) A. S. Tanenbaum. <i>Computer 
Networks</i>, op. cit., 1996, p. 40. 
</p><p align="JUSTIFY">(21) Uma função exponencial é uma função da forma 
<i>f</i>(<i>t</i>) = exp (<i>at</i> + <i>b</i>) onde 
<i>a </i> 0 e <i>b</i> são constantes e exp 
(<i>x</i>) representa <i>e </i>elevado a <i>x</i>. Todas as funções exponenciais são monotônicas, podendo 
ser crescentes (se <i>a</i> &gt; 0) ou decrescentes (se 
<i>a</i> &lt; 0).
(22) Inicialmente, a lei foi formulada em termos da complexidade do microchip que iria dobrar a 
cada doze meses. 
</p><p align="JUSTIFY">(23) V. W. S. Chan, "All-optical Networks", in 
<i>Scientific American</i>, 273 (3), September 1995, pp. 
56-9;  A. S. Tanenbaum, <i>Computer Networks</i>, op. cit., 1996, p. 87, 
</p><p align="JUSTIFY">(24) V. W. S. Chan, "All-optical Networks", op. cit.; D. A. Patterson, "Microprocessors in 2020", 
in <i>Scientific American</i>, 273 (3), September 1995, pp. 48­51.  
</p><p align="JUSTIFY">(25) J. L. Hennessy and D. A. Patterson, 
<i>Computer Architecture: A Quantitative 
Approach</i>, Morgan Kaufmann Pub., 2nd edition, 1996. 
</p><p align="JUSTIFY">(26) Network Wizards, Internet Domain Survey. http://www.nw.com/zone/WWW/top.html.A. 
M. Rutkowski, Internet Trends. http://www.genmagic.com/Internet/Trends/.R. Zakon. Hobbes' 
Internet Timeline. http://www.isoc.org/zakon/Internet/History/HIT. html. 
</p><p align="JUSTIFY">(27) M. Gray, Internet statistics: Web growth, internet growth. 
http://www.mit.edu/people/mkgray/net/.R. Zakon, Hobbes' Internet Timeline. http://www.isoc.org/zakon/Internet/History/HIT. html. 
</p><p align="JUSTIFY">(28) J. von Neumann, "Defense in Atomic War", in 
<i>Journ. Am. Ordnance Assoc. Washington, DC</i>, 1995, pp. 21-3. 
</p><p align="JUSTIFY">(29) J. Licklider, <i>Libraries of the 
Future</i>, Cambridge, The MIT Press, MA, 1965. 
</p><p align="JUSTIFY">(30) A. Goldberg (ed.), <i>A History of Personal 
Workstations</i>. Addison-Wesley, Reading, MA, 1988;  
H. H. Goldstine, <i>The Computer from Pascal to von 
Neumann</i>, Princeton University Press, 1972; T. Kowaltowski, "Von Neumann: suas Contribuições à Computação", in 
<i>Estudos Avançados</i>, 10 (26), 1996, pp.  237-60; N. Metropolis, J. Howlett, and G.-C. Rota (eds.), 
<i>A History of Computing in the Twentieth 
Century</i>, New York,  Academic Press, 1980; L. Press, "Before the Altair ­ the History 
of Personal Computing", in <i>Communications of the 
ACM</i>, 36 (9), 1993, pp. 27-33; B. Randell (ed.), 
<i>The Origins of Digital Computers</i>, Third Edition, Springer-Verlag, 1982. 
</p><p align="JUSTIFY">(31) T. Kowaltowski, "Von Neumann: suas Contribuições à Computação", op. cit.
</p><p align="JUSTIFY">(32) J. Licklider, "Man-computer Symbiosis", in 
<i>IRE Transactions on Human Factors in 
Electronics</i>, March 1960, pp. 4-11; idem, <i>Libraries of the Future, 
</i>op. cit.; idem, "Some Reflections on 
Early History", in A. Goldberg (ed.), <i>A History of Personal 
Workstations</i>, pp. 115-30. Addison-Wesley, Reading, MA, 1988.       
</p><p align="JUSTIFY">(33) L. Roberts, "The Arpanet and Computer Networks", in A. Goldberg (ed.), 
<i>A History of Personal Workstations</i>, op. cit., pp. 141-71. 
</p><p align="JUSTIFY">(34) P. Baran, <i>On Distributed Communications Networks. Technical Report RAND Paper 
P-2626, </i>RAND Corp.<i>,</i> Santa Monica, CA, Sept. 1962. 
</p><p align="JUSTIFY">(35) L. Roberts, "The Arpanet and Computer Networks", op. cit., p. 150. 
</p><p align="JUSTIFY">(36) D. E. Comer, "A Computer Science Research Network CSnet: A History and Status Report", 
in <i>Communications of the ACM</i>, 26, 1983, pp. 747-53.
</p><p align="JUSTIFY">(37) J. S. Quarterman and J. C. Hoskins, "Notable Computer Networks", in 
<i>Communications of the ACM</i>, 29, 1986, pp. 932-71. 
</p><p align="JUSTIFY">(38) Idem, ibidem. 
</p><p align="JUSTIFY">(39) D. Frey and R. Adams, !%@:: 
<i>A Directory of Electronic Mail Addressing and 
Networks</i>, Sebastopol, CA, O'Reilly &amp; Associates, Inc.,  1989.          
</p><p align="JUSTIFY">(40)  K. D. Frazer, "NSFnet: A Partnership for High-speed Networking, Final Report 
1987-1995", Merit Network Inc., 1996. 
</p><p align="JUSTIFY">(41) A primeira referência que conhecemos à palavra Internet ocorre na RFC 675 de 
1<u><sup>o</sup></u> de dezembro de 1974. 
</p><p align="JUSTIFY">(42) J. Martin, <i>Cybercorp, the New Business 
Revolution</i>, New York,  American Management 
Association, 1996. 
</p><p align="JUSTIFY">(43) R. Bernard, <i>Corporate 
Intranet</i>, John Wiley &amp; Sons, Inc., 1996. 
</p><p align="JUSTIFY">(44) T. Berners-Lee, R. Cailliau, A. Loutonen, H. F. Nielsen, and A. Secret, "The World-Wide 
Web", in <i>Communications of the ACM</i>, 37, 1994, pp. 76-82.           
</p><p align="JUSTIFY">(45) R. Seltzer, E. J. Ray, and D. S. Ray. 
<i>The AltaVista Search Revolution</i>, op. cit. 
</p><p align="JUSTIFY">(46) Comitê Gestor Internet Brasil. http://www.cg.org.br/. 
</p><p align="JUSTIFY">(47) I. M. Campos, An External View. http://www. farnet. org/cheyenne/campos/. 
(48) R. Kling (ed.), <i>Computerization and Controversy, Value Conflicts and Social 
Choices</i>, San Diego, Academic Press, 1996; K. Sale. 
<i>Rebels Against the Future. The Luddites and Their War on the 
Industrial Revolution. Lessons for the Computer 
Age</i>,  Reading, MA, Addison-Wesley Pu. Co., 1996. 
</p><p align="JUSTIFY">(49) R. Kraut, "The Internet@Home", op. cit.
</p><p align="JUSTIFY">(50)A. M. Odlyzko, "Tragic Loss or Good Riddance? The Impending Demise of Traditional 
Scholarly Journals", in <i>J. Univ. Comp. 
Sci.</i>, 0 (0), 1994, pp. 3-53, http://www.iicm.edu/jucs. 
</p><p align="JUSTIFY">(51) J. J. Dongarra, Performance of Various Computers Using Standard Linear Equations 
Software, 1996. http://www.netlib.org/benchmark/performance.ps. 
</p><p align="JUSTIFY">(52) Amazon.com Books. http://www.amazon.com/.CDnow: Main: Homepage. 
http://www.cdnow.com/.Leite fazenda ­ menu. http://www.leitefazenda.com.br/menu.htm.Bem-vindo ao Pão de 
Açúcar. http://www2.uol.com.br/pda/.Virtual Vineyards. 
http://www.virtualvin.com/. 
</p><p align="JUSTIFY">(53) Millicent. http://www.research.digital.com/SRC/millicent/.The Information Economy. 
http://www.sims.berkeley.edu/resources/infoecon/. 
</p><p align="JUSTIFY">(54) World Intellectual Property Organization (WIPO). http://www.wipo.org/eng/. 
</p><p align="JUSTIFY">(55) P. R. Zimmermann, <i>The Official PGP User's 
Guide</i>, Cambridge, MA,  The MIT Press, 1995. 
</p><p align="JUSTIFY">(56) V. W. S. Chan,  "All-optical Networks", op. cit.; A. S. Tanenbaum, 
<i>Computer Networks,</i> op. cit., 1996, p. 87. 
</p><p align="JUSTIFY">(57) G. I. Zysman, "Wireless Networks", in 
<i>Scientific American</i>, 273 (3), September 1995, pp. 52-5. 
</p><p align="JUSTIFY">(58) D. Getschko, "Contribuições ao Problema da Última Milha". 
http://www.cg.org.br/artigos/doc8.htm, 1996. 
</p><p align="JUSTIFY">(59) A. S. Tanenbaum, <i>Computer 
Networks</i>, op. cit., 1996, pp. 61 e 144.     
</p><p align="JUSTIFY">(60) Adaptive Networks, Inc. 
http://www.adaptivenetworks.com/. 
</p><p align="JUSTIFY">(61) Amazon.com Books. http://www.amazon.com/.                
</p><p align="JUSTIFY">(62) R. Bernard, <i>Corporate 
Intranet</i>, John Wiley &amp; Sons, Inc., 1996;  M. Hills, 
<i>Intranet as Groupware</i>, New York, John Wiley &amp; Sons, Inc., 1997. http://www.wiley.com/compbooks/. 
</p><p align="JUSTIFY">(63) D. A. Patterson, "Microprocessors in 2020", in 
<i>Scientific American</i>, 273 (3), September 1995, 
pp. 48-51. 
</p><p align="JUSTIFY">(64) J. Licklider, <i>Libraries of the 
Future</i>, op. cit. 
</p><p align="JUSTIFY">(65) Adaptive Networks, Inc. 
http://www.adaptivenetworks.com/. 
</p><p align="JUSTIFY">(66) P. J. Denning and J. M. Metcalfe (eds.), 
<i>Beyond Calculation: The Next 50 Years of 
Computing</i>, Copernicus Books (Springer-Verlag), 1997. 
</p><p align="JUSTIFY">(67) Maiores informações podem ser encontradas em: The ACM97 Conference. 
http://www.acm.org/acm97.
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><i>(Este trabalho foi substancialmente enriquecido por inúmeras observações e contribuições que 
os autores receberam de Eduardo Bonilha de Toledo Leite, Hartmut Richard Glaser, Istvan Simon, 
Janos Simon, Jean-Eric Pin, Marília Junqueira Caldas, Martin Grossmann, Nicolau Reinhard, Demi 
Getschko, Siang Wun Song e Tomasz Kowaltowski. Os autores agradecem efusivamente essas contribuições.
</i></p><p align="JUSTIFY"><i>Uma versão preliminar deste documento serviu de base para um debate no simpósio "A 
Importância da Ciência para o Desenvolvimento Nacional", organizado pela Academia Brasileira de 
Ciências, dentro das comemorações dos seus 80 anos de existência. O simpósio foi realizado de 5 a 7 de 
março de 1997, na Universidade de São Paulo. Os debatedores foram os acadêmicos Carlos José Pereira 
de Lucena, Clovis Gonzaga e José Ellis Ripper Filho.)</i>
</p><p align="JUSTIFY">
</p><p align="JUSTIFY">Este trabalho está sendo reimpresso com a autorização da Academia Brasileira de Ciências.
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>ARNALDO MANDEL</b> é professor do Instituto de Matemática e Estatística da USP. 
</p><p align="JUSTIFY"><i>e-mail</i>:<i> </i>am@ime.usp.br
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>IMRE SIMON </b>é presidente da Comissão Central de Informática da USP.
</p><p align="JUSTIFY"><i>e-mail</i>: is@ime.usp.br
</p><p align="JUSTIFY">
</p><p align="JUSTIFY"><b>JORGE L. DELYRA </b>é professor do Instituto de Física da USP. 
</p><p align="JUSTIFY"><i>e-mail</i>: delyra@fma.if.usp.br
<br><br><a href="http://www.ime.usp.br/~is/infousp/abertur.htm"><img src="./INFORMAÇÃO_COMPUTAÇÃO E COMUNICAÇÃO(ARNALDO MANDEL, IMRE SIMON E JORGE L.DE LYRA )_files/cobral01.gif" border="0"></a></p></td><td colspan="1" height="665">
</td></tr><tr valign="TOP" align="LEFT">
<td colspan="1" height="18">
</td></tr><tr valign="TOP" align="LEFT">
<td colspan="2">
</td><td colspan="1" height="19" width="29" valign="TOP">
<p align="CENTER">
</p></td><td colspan="1" height="19">
</td></tr><tr valign="TOP" align="LEFT">
<td colspan="1" height="21">
</td></tr></tbody></table>

</body></html>